{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d211c5-bc7a-41ff-a03d-f0241ca19ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e404e043-f757-4683-bcf1-bafb3d084a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logging for cleaner output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# Suppress GPR numerical warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- Final Submission Configuration ---\n",
    "DATA_FILE_PATH = 'bbo_master_w06.csv' \n",
    "OUTPUT_DIR = 'add_data'\n",
    "OUTPUT_FILE_NAME = 'week06_clean_inputs.json'\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILE_NAME)\n",
    "\n",
    "# Final exploitation strategy: Matern 2.5 for high-precision local exploitation.\n",
    "OPTIMAL_KERNEL = Matern(length_scale=1.0, nu=2.5) \n",
    "NUM_MULTI_STARTS = 50 \n",
    "MAX_COORD_VALUE = 0.999999 # Mandatory cap for submission\n",
    "\n",
    "# Define the domain (dimensionality) for each function\n",
    "FUNCTION_DIMS: Dict[int, int] = {\n",
    "    1: 2, 2: 2, 3: 3, 4: 4, 5: 4, 6: 5, 7: 6, 8: 8\n",
    "}\n",
    "ALL_FUNCTION_IDS = list(FUNCTION_DIMS.keys())\n",
    "ALL_X_COLS = [f'X{i}' for i in range(1, 9)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79944d1a-5a35-4396-9565-5cce923426fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Acquisition Function: Expected Improvement (EI) ---\n",
    "\n",
    "def expected_improvement(X: np.ndarray, gpr: GaussianProcessRegressor, f_best: float) -> np.ndarray:\n",
    "    \"\"\"Calculates the Expected Improvement (EI) for a given point X.\"\"\"\n",
    "    mu, sigma = gpr.predict(X.reshape(1, -1), return_std=True)\n",
    "    \n",
    "    # Handle near-zero sigma to avoid division by zero\n",
    "    if sigma.any() < 1e-10:\n",
    "        return np.array([0.0])\n",
    "\n",
    "    Z = (mu - f_best) / sigma\n",
    "    ei = (mu - f_best) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3981cc-3cfd-43e3-a18a-597e63c356cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Optimization Function ---\n",
    "\n",
    "def optimize_acquisition(func_id: int, gpr: GaussianProcessRegressor, f_best: float) -> List[float]:\n",
    "    \"\"\"Finds the next optimal query point X by maximizing the Expected Improvement.\"\"\"\n",
    "    \n",
    "    D = FUNCTION_DIMS[func_id]\n",
    "    acq_func = lambda X: -expected_improvement(X, gpr, f_best) \n",
    "    bounds = [(0, 1)] * D # Optimization operates on the open interval [0, 1] \n",
    "    \n",
    "    best_x = None\n",
    "    best_acq_value = np.inf\n",
    "    \n",
    "    # Multi-start optimization loop (50 starts for maximum precision)\n",
    "    for i in range(NUM_MULTI_STARTS):\n",
    "        x0 = np.random.uniform(0, 1, D)\n",
    "        res = minimize(\n",
    "            acq_func,\n",
    "            x0,\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success and res.fun < best_acq_value:\n",
    "            best_acq_value = res.fun\n",
    "            best_x = res.x\n",
    "            \n",
    "    if best_x is None:\n",
    "        logging.warning(f\"  Warning: Optimization failed for F{func_id}. Using random start.\")\n",
    "        best_x = np.random.uniform(0, 1, D)\n",
    "        \n",
    "    return best_x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c12191-eb97-4f0a-a56f-915bb11cbbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_week06_queries() -> List[List[float]]:\n",
    "    \"\"\"Main function to load data, train GPRs, and generate 8 new queries with final formatting.\"\"\"\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df_master = pd.read_csv(DATA_FILE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"FATAL: Master data file not found at '{DATA_FILE_PATH}'.\")\n",
    "        return []\n",
    "\n",
    "    df_clean = df_master.copy()\n",
    "    for col in ALL_X_COLS:\n",
    "        # Fill non-numeric (NaN/empty string) with 0.0 for GPR training\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "    all_queries_raw = []\n",
    "    \n",
    "    logging.info(\"\\n\" + \"=\"*70)\n",
    "    logging.info(f\"== Generating 8 FINAL Week 6 Queries (Matern 2.5 + EI + {NUM_MULTI_STARTS} Multi-Starts) ==\")\n",
    "    logging.info(\"=\"*70)\n",
    "\n",
    "    for func_id in ALL_FUNCTION_IDS:\n",
    "        # 2. Prepare function-specific data\n",
    "        df_func = df_clean[df_clean['Function ID'] == func_id]\n",
    "        D = FUNCTION_DIMS[func_id]\n",
    "        X_cols_relevant = ALL_X_COLS[:D]\n",
    "        X = df_func[X_cols_relevant].values\n",
    "        Y = df_func['Y'].values.reshape(-1, 1)\n",
    "\n",
    "        f_best = np.max(Y)\n",
    "        \n",
    "        # 3. Train the GPR Model\n",
    "        gpr = GaussianProcessRegressor(\n",
    "            kernel=OPTIMAL_KERNEL, \n",
    "            n_restarts_optimizer=5, \n",
    "            alpha=1e-8\n",
    "        )\n",
    "        gpr.fit(X, Y)\n",
    "\n",
    "        # 4. Optimize Acquisition Function\n",
    "        query_x_list = optimize_acquisition(func_id, gpr, f_best)\n",
    "\n",
    "        # 5. Format and Finalise Query: Pad, Clip (0.999999), and Round (6-digit precision)\n",
    "        \n",
    "        # Clip values to the mandatory max and min\n",
    "        clipped_query = [np.clip(x, 0.0, MAX_COORD_VALUE) for x in query_x_list]\n",
    "        \n",
    "        # Format to 6 decimal places\n",
    "        formatted_query = [round(x, 6) for x in clipped_query]\n",
    "        \n",
    "        # Pad with 0.0 to 8 dimensions\n",
    "        padded_query = formatted_query + [0.0] * (8 - D)\n",
    "        all_queries_raw.append(padded_query)\n",
    "        \n",
    "        # Log the generated query (showing first few dimensions)\n",
    "        logging.info(f\"F{func_id} ({D}D): f_best={f_best:.4f}. Next Query X1-X{D}: {[f'{x:.6f}' for x in formatted_query[:3]]}...\")\n",
    "\n",
    "    # 6. Save the final queries to JSON\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    with open(OUTPUT_PATH, 'w') as f:\n",
    "        # Custom JSON dumping to ensure the output format is a clean array of arrays\n",
    "        json.dump(all_queries_raw, f, indent=2)\n",
    "        \n",
    "    logging.info(\"\\n\" + \"-\"*70)\n",
    "    logging.info(f\"SUCCESS: Generated 8 FINAL queries for Week 6.\")\n",
    "    logging.info(f\"File saved to: '{OUTPUT_PATH}'. This is the file to submit.\")\n",
    "    logging.info(\"-\" * 70)\n",
    "    \n",
    "    return all_queries_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f8e99f-2575-44f3-9404-53e02455e5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "======================================================================\n",
      "INFO: == Generating 8 FINAL Week 6 Queries (Matern 2.5 + EI + 50 Multi-Starts) ==\n",
      "INFO: ======================================================================\n",
      "INFO: F1 (2D): f_best=0.1744. Next Query X1-X2: ['0.000000', '0.999999']...\n",
      "INFO: F2 (2D): f_best=0.6660. Next Query X1-X2: ['0.535953', '0.318272']...\n",
      "INFO: F3 (3D): f_best=-0.0200. Next Query X1-X3: ['0.999999', '0.999999', '0.000000']...\n",
      "INFO: F4 (4D): f_best=-2.9741. Next Query X1-X4: ['0.101075', '0.813896', '0.853852']...\n",
      "INFO: F5 (4D): f_best=4440.4809. Next Query X1-X4: ['0.362040', '0.663433', '0.665456']...\n",
      "INFO: F6 (5D): f_best=-0.7143. Next Query X1-X5: ['0.000000', '0.000000', '0.999999']...\n",
      "INFO: F7 (6D): f_best=1.6487. Next Query X1-X6: ['0.540511', '0.127780', '0.698166']...\n",
      "INFO: F8 (8D): f_best=9.9951. Next Query X1-X8: ['0.067152', '0.242506', '0.000000']...\n",
      "INFO: \n",
      "----------------------------------------------------------------------\n",
      "INFO: SUCCESS: Generated 8 FINAL queries for Week 6.\n",
      "INFO: File saved to: 'add_data/week06_clean_inputs.json'. This is the file to submit.\n",
      "INFO: ----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    generate_week06_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65fbad-54f6-4fe8-b425-68942b3c005d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
