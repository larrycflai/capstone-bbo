{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297f18e1-9ee0-430e-b4b2-a455e7f61a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting BBO Query Generation ---\n",
      "INFO: Reading data from local file: bbo_master_w09.csv\n",
      "INFO: Loaded master data with 144 total rows.\n",
      "\n",
      "--- Function Dimensionality Analysis ---\n",
      "INFO: Function F1 (2D) has 18 data points.\n",
      "INFO: Function F2 (2D) has 18 data points.\n",
      "INFO: Function F3 (3D) has 18 data points.\n",
      "INFO: Function F4 (4D) has 18 data points.\n",
      "INFO: Function F5 (4D) has 18 data points.\n",
      "INFO: Function F6 (5D) has 18 data points.\n",
      "INFO: Function F7 (6D) has 18 data points.\n",
      "INFO: Function F8 (8D) has 18 data points.\n",
      "------------------------------------------\n",
      "--- Generating Queries for Round 9 Submission (add_data/week09_clean_inputs.json) ---\n",
      "F1 (2D): [0.420183, 0.363239]\n",
      "F2 (2D): [0.093108, 0.971656]\n",
      "F3 (3D): [0.08735, 0.230477, 0.411061]\n",
      "F4 (4D): [0.924035, 0.157871, 0.866915, 0.084157]\n",
      "F5 (4D): [0.300873, 0.186946, 0.323183, 0.66575]\n",
      "F6 (5D): [0.033755, 0.489108, 0.846085, 0.411402, 0.631415]\n",
      "F7 (6D): [0.379099, 0.567098, 0.595593, 0.449859, 0.45702, 0.311651]\n",
      "F8 (8D): [0.545851, 0.858857, 0.685893, 0.331592, 0.059998, 0.386278, 0.21315, 0.932507]\n",
      "------------------------------------------\n",
      "SUCCESS: Generated 8 FINAL queries with correct dimensions.\n",
      "File saved to: add_data/week09_clean_inputs.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILENAME = \"bbo_master_w09.csv\"\n",
    "OUTPUT_FILENAME = \"week09_clean_inputs.json\" # Filename reverted to maintain naming consistency\n",
    "OUTPUT_DIR = \"add_data\" # New directory variable\n",
    "ROUND_NUMBER = 9\n",
    "NUM_FUNCTIONS = 8\n",
    "# --- End Configuration ---\n",
    "\n",
    "def determine_dimensions(df, func_id):\n",
    "    \"\"\"\n",
    "    Determines the correct dimensionality for a given Function ID.\n",
    "    The dimension is the highest X-column (X1 to X8) that contains at least one\n",
    "    non-NaN/non-zero-like value for that function ID.\n",
    "    \"\"\"\n",
    "    func_data = df[df['Function ID'] == func_id]\n",
    "    \n",
    "    # Define X columns to check\n",
    "    x_cols = [f'X{i}' for i in range(1, 9)]\n",
    "    \n",
    "    # Check for non-null/non-zero data in each dimension\n",
    "    dimension = 0\n",
    "    for i, col in enumerate(x_cols):\n",
    "        # Check if the column exists in the DataFrame and if it contains\n",
    "        # any value that is NOT NaN/None, or is non-zero (if it's a number).\n",
    "        if col in func_data.columns and func_data[col].notna().any():\n",
    "            # Check for non-zero data specifically, as some datasets pad with 0.0\n",
    "            # Convert to numeric, errors='coerce' to handle non-numeric 'nulls'\n",
    "            numeric_data = pd.to_numeric(func_data[col], errors='coerce').fillna(0)\n",
    "            \n",
    "            # If any value is significantly non-zero (or just not null/empty),\n",
    "            # we consider this dimension active.\n",
    "            if (numeric_data.abs() > 1e-9).any():\n",
    "                dimension = i + 1\n",
    "            elif func_data[col].astype(str).str.strip().str.len().max() > 0:\n",
    "                 # Catch cases where the column is populated by non-numeric strings but is present\n",
    "                 dimension = i + 1\n",
    "        else:\n",
    "             # Stop checking if the column itself is missing or entirely NaN\n",
    "            break\n",
    "            \n",
    "    # --- HARDCODED DIMENSION OVERRIDES BASED ON BBO ROUND 9 REQUIREMENTS ---\n",
    "    # F1: 2D (Default/Data-driven)\n",
    "    # F2: 2D (Default/Data-driven)\n",
    "    # F3: 3D (Default/Data-driven)\n",
    "    if func_id == 4: # Enforce F4 as 4D\n",
    "        return 4\n",
    "    if func_id == 5: # Enforce F5 as 4D\n",
    "        return 4\n",
    "    if func_id == 6: # Enforce F6 as 5D (NEW CHANGE)\n",
    "        return 5\n",
    "    if func_id == 7: # Enforce F7 as 6D (NEW CHANGE)\n",
    "        return 6\n",
    "    if func_id == 8: # Enforce F8 as 8D\n",
    "        return 8\n",
    "    # --- END OVERRIDES ---\n",
    "    \n",
    "    # Fallback/Default dimension logic\n",
    "    if dimension < 2 and func_data.shape[0] > 0:\n",
    "        return 2\n",
    "\n",
    "    return dimension if dimension >= 2 else 2 # Default to 2D if nothing else found\n",
    "\n",
    "\n",
    "def generate_random_query(func_id, dimension):\n",
    "    \"\"\"\n",
    "    Generates a random query list of the specified dimension, rounded to 6 decimal places.\n",
    "    The seed now includes the unique func_id to ensure every query is different.\n",
    "    \"\"\"\n",
    "    # Using func_id in the seed guarantees unique sequences for F1, F2, F3, etc.\n",
    "    np.random.seed(42 + func_id + dimension + ROUND_NUMBER) \n",
    "    return [round(np.random.rand(), 6) for _ in range(dimension)]\n",
    "\n",
    "\n",
    "def generate_queries(csv_data_source):\n",
    "    \"\"\"\n",
    "    Main function to analyze the data and generate the submission queries.\n",
    "    It accepts either raw CSV content (for the collaborative platform) or a file path.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting BBO Query Generation ---\")\n",
    "    \n",
    "    try:\n",
    "        if isinstance(csv_data_source, str) and os.path.exists(csv_data_source):\n",
    "            # Case 1: Running locally - read from file path\n",
    "            print(f\"INFO: Reading data from local file: {csv_data_source}\")\n",
    "            df = pd.read_csv(csv_data_source)\n",
    "        elif isinstance(csv_data_source, str):\n",
    "            # Case 2: Running in environment (e.g., in this chat) - read from raw content\n",
    "            print(\"INFO: Reading data from environment content string.\")\n",
    "            df = pd.read_csv(StringIO(csv_data_source))\n",
    "        else:\n",
    "             raise ValueError(\"Invalid CSV data source provided.\")\n",
    "        \n",
    "        # Ensure column names are stripped of whitespace\n",
    "        df.columns = df.columns.str.strip()\n",
    "        print(f\"INFO: Loaded master data with {len(df)} total rows.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not load or parse CSV data: {e}. Please ensure '{CSV_FILENAME}' is in the correct directory.\")\n",
    "        return {}\n",
    "\n",
    "    # 1. Determine Correct Dimensions for all functions\n",
    "    function_dims = {}\n",
    "    \n",
    "    print(\"\\n--- Function Dimensionality Analysis ---\")\n",
    "    \n",
    "    # Iterate through all function IDs\n",
    "    for func_id in range(1, NUM_FUNCTIONS + 1):\n",
    "        function_id_col = 'Function ID' if 'Function ID' in df.columns else 'FunctionID'\n",
    "        \n",
    "        if function_id_col in df.columns and func_id in df[function_id_col].unique():\n",
    "            # Get dimension (will use the hardcoded override inside the function)\n",
    "            dim = determine_dimensions(df.rename(columns={function_id_col: 'Function ID'}), func_id)\n",
    "            \n",
    "            function_dims[f'F{func_id}'] = (dim, func_id) # Store both dim and ID\n",
    "            # Check if there is data for this function\n",
    "            num_points = df[df[function_id_col] == func_id].shape[0]\n",
    "            print(f\"INFO: Function F{func_id} ({dim}D) has {num_points} data points.\")\n",
    "        else:\n",
    "            # Fallback logic for IDs not found, ensuring the correct dimension is used\n",
    "            if func_id == 4: dim = 4\n",
    "            elif func_id == 5: dim = 4\n",
    "            elif func_id == 6: dim = 5 # Use 5D for F6 fallback\n",
    "            elif func_id == 7: dim = 6 # Use 6D for F7 fallback\n",
    "            elif func_id == 8: dim = 8\n",
    "            else: dim = 2\n",
    "            \n",
    "            function_dims[f'F{func_id}'] = (dim, func_id) # Store both dim and ID\n",
    "            print(f\"INFO: Function F{func_id} defaulting to: {dim}D (ID not found in current dataset, using BBO default dimension).\")\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    # 2. Generate Random Queries with the Correct Dimensions\n",
    "    final_queries = {}\n",
    "    print(f\"--- Generating Queries for Round {ROUND_NUMBER} Submission ({OUTPUT_DIR}/{OUTPUT_FILENAME}) ---\")\n",
    "    for func_name, (dim, func_id) in function_dims.items():\n",
    "        # Pass both the ID and the dimension for unique seeding\n",
    "        query = generate_random_query(func_id, dim) \n",
    "        final_queries[func_name] = query\n",
    "        print(f\"{func_name} ({dim}D): {query}\")\n",
    "\n",
    "    # 3. Save the result as JSON list of lists in the specified subfolder\n",
    "    \n",
    "    # Construct the final list of lists in order F1 to F8\n",
    "    ordered_queries = [final_queries[f'F{i}'] for i in range(1, NUM_FUNCTIONS + 1)]\n",
    "    \n",
    "    output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Save the data\n",
    "    try:\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(ordered_queries, f, indent=4)\n",
    "        \n",
    "        print(\"------------------------------------------\")\n",
    "        print(f\"SUCCESS: Generated {len(ordered_queries)} FINAL queries with correct dimensions.\")\n",
    "        print(f\"File saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save the JSON file to {output_path}. Error: {e}\")\n",
    "    \n",
    "    return final_queries\n",
    "\n",
    "\n",
    "# --- Execution Block ---\n",
    "# This block handles the different ways the script can be run.\n",
    "\n",
    "# 1. Check for the collaborative environment file handler (if running in the chat platform)\n",
    "try:\n",
    "    # Use the content provided by the collaborative environment\n",
    "    if '__files__' in globals() and CSV_FILENAME in __files__:\n",
    "        csv_content = __files__[CSV_FILENAME]['content']\n",
    "        generate_queries(csv_content)\n",
    "    else:\n",
    "        # 2. If running in the collaborative environment but file handle is missing (or running locally)\n",
    "        # Attempt to read the file directly using the filename (for local execution)\n",
    "        generate_queries(CSV_FILENAME)\n",
    "\n",
    "except NameError:\n",
    "    # 3. Running outside the collaborative environment (e.g., local IDE/notebook)\n",
    "    # The '__files__' variable is not defined, so fall back to reading the file directly.\n",
    "    generate_queries(CSV_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
