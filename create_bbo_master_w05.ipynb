{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99e8112-0835-4f3d-874d-2627eee99367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a89bac3-79b5-49dd-960d-921197c09cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logging for cleaner output during executiion\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(levelname)s: %(message)s')\n",
    "\n",
    "# --- Configuration ---\n",
    "OLD_MASTER_FILE = 'bbo_master_w04.csv'\n",
    "NEW_MASTER_FILE = 'bbo_master_w05.csv'\n",
    "ADD_DATA_DIR = 'add_data'\n",
    "INPUT_FILE = os.path.join(ADD_DATA_DIR, 'week04_clean_inputs.json')\n",
    "OUTPUT_FILE = os.path.join(ADD_DATA_DIR, 'week04_clean_outputs.json')\n",
    "\n",
    "# Expected rows: 80 initial + 4 queries * 8 functions = 112\n",
    "EXPECTED_OLD_ROWS = 104\n",
    "NEW_ROWS_COUNT = 8\n",
    "EXPECTED_NEW_ROWS = EXPECTED_OLD_ROWS + NEW_ROWS_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7736388f-f385-40b3-9468-c7211cce644d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bbo_master_w05():\n",
    "    \"\"\"Loads the old master file, appends Week 4 query data, and saves the\n",
    "    new master file.\"\"\"\n",
    "    \n",
    "    # 1. Load existing master file\n",
    "    try:\n",
    "        df_old = pd.read_csv(OLD_MASTER_FILE)\n",
    "        if len(df_old) != EXPECTED_OLD_ROWS:\n",
    "            logging.warning(f\"WARNING: Loaded {OLD_MASTER_FILE} with {len(df_old)} rows, \" +\n",
    "                            f\" expected {EXPECTED_OLD_ROWS}.\")\n",
    "        else:\n",
    "            logging.info(f\"--- Loading initial data from {OLD_MASTER_FILE} \" +\n",
    "                         f\"(Expected {EXPECTED_OLD_ROWS} rows) ---\")\n",
    "        df_old.replace('', np.nan, inplace=True) # Replace empty strings with NaN for consistency\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"ERROR: Master file {OLD_MASTER_FILE} not found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # 2. Load new input and output data\n",
    "    try:\n",
    "        with open(INPUT_FILE, 'r') as f:\n",
    "            inputs = json.load(f)\n",
    "        with open(OUTPUT_FILE, 'r') as f:\n",
    "            outputs = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"ERROR: One or both new data files ({INPUT_FILE} \" +\n",
    "                      f\"or {OUTPUT_FILE}) not found. Check the 'add_data' folder. Exiting.\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(\"ERROR: Could not parse JSON data from the new files. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    if len(inputs) != NEW_ROWS_COUNT or len(outputs) != NEW_ROWS_COUNT:\n",
    "        logging.error(f\"ERROR: New data files must contain {NEW_ROWS_COUNT} rows \" +\n",
    "                      f\"(one per function). Found {len(inputs)} inputs and \" +\n",
    "                      f\"{len(outputs)} outputs. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # 3. Create new DataFrame for the Week 4 query\n",
    "    new_data = []\n",
    "    for i in range(NEW_ROWS_COUNT):  # Iterate through F1 to F8 (i=0 to 7)\n",
    "        row = {'Function ID': i + 1, 'Y': outputs[i]}\n",
    "        \n",
    "        # The input array has length D (2 to 8). Fill X1..X8\n",
    "        input_array = inputs[i]\n",
    "        for j in range(8):\n",
    "            col_name = f'X{j+1}'\n",
    "            if j < len(input_array):\n",
    "                row[col_name] = input_array[j]\n",
    "            else:\n",
    "                # Empty columns for lower dimensional functions\n",
    "                row[col_name] = np.nan\n",
    "                \n",
    "        new_data.append(row)\n",
    "        \n",
    "    df_new = pd.DataFrame(new_data)\n",
    "    # Ensure column order matches the master file structure\n",
    "    df_new = df_new[['Function ID', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y']]\n",
    "    \n",
    "    logging.info(f\"Successfully loaded {len(df_new)} new Week 4 query points \" +\n",
    "                 f\"from '{ADD_DATA_DIR}' (F1-F8).\")\n",
    "    \n",
    "    # 4. Append and save\n",
    "    df_master = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    \n",
    "    # Sanity check\n",
    "    if len(df_master) != EXPECTED_NEW_ROWS:\n",
    "        logging.warning(f\"WARNING: Total row count is {len(df_master)}, \" +\n",
    "                        f\"expected {EXPECTED_NEW_ROWS}.\")\n",
    "    \n",
    "    # Use a high float precision for the values\n",
    "    df_master.to_csv(NEW_MASTER_FILE, index=False, float_format='%.17f')\n",
    "    \n",
    "    logging.info(\"INFO: ----------------------------------------------\")\n",
    "    logging.info(f\"SUCCESS: New master data file '{NEW_MASTER_FILE}' created.\")\n",
    "    logging.info(f\"Total rows in the new file: {len(df_master)} (Expected {EXPECTED_NEW_ROWS}).\")\n",
    "    logging.info(f\"Verification: There're now {len(df_master) / 8} data points for each function.\")\n",
    "    logging.info(\"INFO: ----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba9c7a0-ad47-4e04-a35f-1219a4909c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: --- Loading initial data from bbo_master_w04.csv (Expected 104 rows) ---\n",
      "INFO: Successfully loaded 8 new Week 4 query points from 'add_data' (F1-F8).\n",
      "INFO: INFO: ----------------------------------------------\n",
      "INFO: SUCCESS: New master data file 'bbo_master_w05.csv' created.\n",
      "INFO: Total rows in the new file: 112 (Expected 112).\n",
      "INFO: Verification: There're now 14.0 data points for each function.\n",
      "INFO: INFO: ----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    create_bbo_master_w05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391ad87-9ea8-4de4-a2c7-4cee547d7ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
