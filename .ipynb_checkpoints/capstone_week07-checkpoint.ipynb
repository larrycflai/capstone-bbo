{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41b7d80-4946-47db-b768-7af0f06c8a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "--- Processing Function F1 (D=2) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.8863\n",
      "INFO: Optimal EI found: 0.0000\n",
      "INFO: F1 (2D): f_best=0.1744. Next Query X1-X2: ['0.239825', '0.486074']...\n",
      "INFO: \n",
      "--- Processing Function F2 (D=2) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -15.3497\n",
      "INFO: Optimal EI found: 0.0019\n",
      "INFO: F2 (2D): f_best=0.6660. Next Query X1-X2: ['0.917077', '0.459697']...\n",
      "INFO: \n",
      "--- Processing Function F3 (D=3) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.6805\n",
      "INFO: Optimal EI found: 0.0229\n",
      "INFO: F3 (3D): f_best=-0.0200. Next Query X1-X3: ['0.528145', '0.578868', '0.510550']...\n",
      "INFO: \n",
      "--- Processing Function F4 (D=4) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -13.6857\n",
      "INFO: Optimal EI found: 1.8692\n",
      "INFO: F4 (4D): f_best=-2.9741. Next Query X1-X4: ['0.375246', '0.298707', '0.306354', '0.661866']...\n",
      "INFO: \n",
      "--- Processing Function F5 (D=4) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.9647\n",
      "INFO: Optimal EI found: 0.0000\n",
      "INFO: F5 (4D): f_best=4440.4809. Next Query X1-X4: ['0.444945', '0.803224', '0.025851', '0.939717']...\n",
      "INFO: \n",
      "--- Processing Function F6 (D=5) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -18.1027\n",
      "INFO: Optimal EI found: 0.0522\n",
      "INFO: F6 (5D): f_best=-0.7143. Next Query X1-X5: ['0.150753', '1.000000', '0.348153', '0.764860', '0.148911']...\n",
      "INFO: \n",
      "--- Processing Function F7 (D=6) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -22.3186\n",
      "INFO: Optimal EI found: 0.0277\n",
      "INFO: F7 (6D): f_best=1.6487. Next Query X1-X6: ['0.326546', '0.400548', '0.705139', '0.083355', '0.406493', '0.059994']...\n",
      "INFO: \n",
      "--- Processing Function F8 (D=8) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -16.0542\n",
      "INFO: Optimal EI found: 0.2246\n",
      "INFO: F8 (8D): f_best=9.9951. Next Query X1-X8: ['0.000000', '0.994502', '0.072091', '0.887942', '0.661276', '0.366557', '0.407295', '0.000000']...\n",
      "INFO: \n",
      "**********************************************************************\n",
      "INFO: SUCCESS: Applying constraint (1.0 -> 0.999999) and saving FINAL queries for Week 7...\n",
      "INFO: File saved to: 'add_data/week07_clean_inputs.json'. This is the file to submit.\n",
      "INFO: **********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Union, Callable\n",
    "\n",
    "# Set up logging for cleaner output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# Suppress GPR numerical warnings and convergence warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# --- Configuration for Final Exploitation Phase (Week 7) ---\n",
    "DATA_FILE_PATH = 'bbo_master_w07.csv' # Input data file\n",
    "ADD_DATA_DIR = 'add_data'\n",
    "OUTPUT_FILE_PATH = os.path.join(ADD_DATA_DIR, 'week07_clean_inputs.json') # Output query file\n",
    "\n",
    "# Define the dimensions (D) for each function (F1 to F8)\n",
    "FUNCTION_DIMS = {\n",
    "    1: 2, 2: 2, 3: 3, 4: 4,\n",
    "    5: 4, 6: 5, 7: 6, 8: 8\n",
    "}\n",
    "\n",
    "# Strategy: Pure Exploitation for final round\n",
    "ACQUISITION_STRATEGIES = {\n",
    "    f_id: 'EI' for f_id in FUNCTION_DIMS.keys()\n",
    "}\n",
    "\n",
    "# --- Acquisition Function Definitions ---\n",
    "\n",
    "def expected_improvement(X_query: np.ndarray, gpr: GaussianProcessRegressor, Y_best: Union[float, None]) -> float:\n",
    "    \"\"\"\n",
    "    Expected Improvement (EI) acquisition function, formulated for MAXIMIZATION.\n",
    "    \n",
    "    Y_best must be the best known *maximum* value.\n",
    "    Returns the NEGATIVE EI, as we use scipy.optimize.minimize to find the maximum.\n",
    "    \"\"\"\n",
    "    if Y_best is None:\n",
    "        return 0.0 \n",
    "\n",
    "    # Predict mean (mu) and standard deviation (sigma)\n",
    "    X_query = np.atleast_2d(X_query)\n",
    "    # The GPR predicts based on the D-dimensional input, not the padded 8D array\n",
    "    mu, sigma = gpr.predict(X_query, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    \n",
    "    # Handle sigma close to zero (already sampled points)\n",
    "    if sigma < 1e-6:\n",
    "        return 0.0\n",
    "    \n",
    "    # Standard calculation of EI\n",
    "    # We use the correct formulation: EI = (mu - Y_best) * Phi(z) + sigma * phi(z)\n",
    "    z = (mu - Y_best) / sigma\n",
    "    \n",
    "    # Normalised CDF (c) = Phi(z) and PDF (p) = phi(z)\n",
    "    c = norm.cdf(z)\n",
    "    p = norm.pdf(z)\n",
    "    \n",
    "    # Expected Improvement formula\n",
    "    ei = (mu - Y_best) * c + sigma * p\n",
    "    \n",
    "    # Return the negative value to MAXIMIZE EI using a MINIMIZER\n",
    "    return -ei \n",
    "\n",
    "# --- Core BBO Functions ---\n",
    "\n",
    "def load_and_preprocess_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads the master CSV file, performs basic cleaning, and scales Y values.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"Data file not found at: {file_path}. Please ensure '{DATA_FILE_PATH}' is available.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    # Replace NaN with 0.0 for X columns (to handle padded dimensions from the master file)\n",
    "    x_cols = [f'X{i}' for i in range(1, 9)]\n",
    "    df[x_cols] = df[x_cols].fillna(0.0)\n",
    "    \n",
    "    # Scale Y to ensure positive values for GPR stability if Y can be heavily negative.\n",
    "    # We maintain the relative order (maximization target remains the same)\n",
    "    df['Y_Scaled'] = df['Y'] - df['Y'].min() + 1e-6\n",
    "    \n",
    "    return df\n",
    "\n",
    "def optimise_acquisition(\n",
    "    gpr: GaussianProcessRegressor, \n",
    "    D: int, \n",
    "    acquisition_func: Callable, \n",
    "    Y_best: Union[float, None] = None\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Minimizes the NEGATIVE acquisition function to find the next query point \n",
    "    that MAXIMIZES the acquisition. This optimization search is ONLY over D dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if acquisition_func == expected_improvement and Y_best is None:\n",
    "        raise ValueError(\"Y_best must be provided for Expected Improvement.\")\n",
    "        \n",
    "    # Define the objective function wrapper for the minimizer\n",
    "    target_func = lambda x: acquisition_func(x, gpr, Y_best)\n",
    "    \n",
    "    # Set bounds: [0, 1] for active dimensions\n",
    "    bounds_active = [(0, 1)] * D\n",
    "    \n",
    "    n_restarts = 10 \n",
    "    best_x_active = None\n",
    "    min_acq_value = np.inf \n",
    "    \n",
    "    for _ in range(n_restarts):\n",
    "        # Initial point x0 for the D active dimensions\n",
    "        x0_active = np.random.uniform(0, 1, D)\n",
    "        \n",
    "        # Use L-BFGS-B for bounded optimization\n",
    "        res = minimize(\n",
    "            fun=target_func, \n",
    "            x0=x0_active, \n",
    "            bounds=bounds_active, \n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success and res.fun < min_acq_value:\n",
    "            min_acq_value = res.fun\n",
    "            best_x_active = res.x\n",
    "            \n",
    "    if best_x_active is None:\n",
    "         # Fallback to a random point if optimisation failed\n",
    "         best_x_active = np.random.uniform(0, 1, D)\n",
    "    \n",
    "    # Combine the D-dimensional result with padded zeros to create the 8D query array\n",
    "    next_query_8d = np.concatenate([best_x_active, np.zeros(8 - D)])\n",
    "        \n",
    "    # Return the 8D query array and the maximum acquisition value (positive)\n",
    "    return next_query_8d, -min_acq_value\n",
    "\n",
    "def constrain_queries(queries: List[List[float]], epsilon: float = 1e-6) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    APPLIES THE CRITICAL CONSTRAINT: 0 <= x_i < 1.\n",
    "    Replaces any value of exactly 1.0 with 1.0 - epsilon.\n",
    "    \"\"\"\n",
    "    constrained_queries = []\n",
    "    for query in queries:\n",
    "        # Ensure x < 1.0 for all dimensions (0.0 padding is unaffected)\n",
    "        constrained_row = [x if x < 1.0 else (1.0 - epsilon) for x in query]\n",
    "        constrained_queries.append(constrained_row)\n",
    "    return constrained_queries\n",
    "\n",
    "def run_optimisation():\n",
    "    \"\"\"Main function to orchestrate the data loading, model training, and query generation.\"\"\"\n",
    "    df_master = load_and_preprocess_data(DATA_FILE_PATH)\n",
    "    if df_master.empty:\n",
    "        return\n",
    "        \n",
    "    all_queries = []\n",
    "    \n",
    "    for f_id, D in FUNCTION_DIMS.items():\n",
    "        logging.info(f\"\\n--- Processing Function F{f_id} (D={D}) ---\")\n",
    "        \n",
    "        # 1. Prepare Data for current function\n",
    "        df_func = df_master[df_master['Function ID'] == f_id].copy()\n",
    "        \n",
    "        # Only use the active dimensions X1 to X_D for training\n",
    "        x_cols = [f'X{i}' for i in range(1, D + 1)]\n",
    "        X_train = df_func[x_cols].values # X_train is correctly D-dimensional\n",
    "        Y_train = df_func['Y_Scaled'].values\n",
    "        \n",
    "        # 2. Train Gaussian Process Regressor (GPR)\n",
    "        # Using Matern kernel (nu=2.5) for general smoothness\n",
    "        kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(D), length_scale_bounds=(1e-3, 1e3), nu=2.5)\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, n_restarts_optimizer=10, normalize_y=True)\n",
    "        \n",
    "        try:\n",
    "            gpr.fit(X_train, Y_train)\n",
    "            logging.info(f\"GPR Model Trained. Log-Marginal-Likelihood: {gpr.log_marginal_likelihood():.4f}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error training GPR for F{f_id}: {e}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Optimise Acquisition Function (Expected Improvement for Week 7)\n",
    "        strategy_name = ACQUISITION_STRATEGIES[f_id]\n",
    "        acq_func = expected_improvement\n",
    "        \n",
    "        Y_best_scaled = np.max(Y_train) # Target is the maximum scaled Y\n",
    "        \n",
    "        # Optimise acquisition to find the next best query point\n",
    "        next_query_8d, optimal_value = optimise_acquisition(gpr, D, acq_func, Y_best_scaled)\n",
    "        \n",
    "        # 4. Format Output and store the 8D float array\n",
    "        all_queries.append([float(x) for x in next_query_8d])\n",
    "        \n",
    "        logging.info(f\"Optimal {strategy_name} found: {optimal_value:.4f}\")\n",
    "        logging.info(f\"F{f_id} ({D}D): f_best={df_func['Y'].max():.4f}. Next Query X1-X{D}: {[f'{x:.6f}' for x in next_query_8d[:D]]}...\")\n",
    "        \n",
    "    # 5. Apply the Constraint: 0 <= x_i < 1\n",
    "    all_queries_constrained = constrain_queries(all_queries, epsilon=1e-6)\n",
    "    \n",
    "    # 6. Save to JSON file\n",
    "    logging.info(\"\\n\" + \"*\" * 70)\n",
    "    logging.info(\"SUCCESS: Applying constraint (1.0 -> 0.999999) and saving FINAL queries for Week 7...\")\n",
    "    \n",
    "    if not os.path.exists(ADD_DATA_DIR):\n",
    "        os.makedirs(ADD_DATA_DIR)\n",
    "        \n",
    "    # Dump the constrained list of lists (8 functions, 8 inputs each)\n",
    "    output_data = [[f'{x:.6f}' for x in query] for query in all_queries_constrained]\n",
    "\n",
    "    with open(OUTPUT_FILE_PATH, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "        \n",
    "    logging.info(f\"File saved to: '{OUTPUT_FILE_PATH}'. This is the file to submit.\")\n",
    "    logging.info(\"*\" * 70)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_optimisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2663a138-1dd8-46ec-807e-f689de509af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "--- Processing Function F1 (D=2) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.8863\n",
      "INFO: Optimal EI found: 0.0000\n",
      "INFO: F1 (2D): f_best=0.1744. Next Query X1-X2: ['0.239825', '0.486074']...\n",
      "INFO: \n",
      "--- Processing Function F2 (D=2) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -15.3497\n",
      "INFO: Optimal EI found: 0.0019\n",
      "INFO: F2 (2D): f_best=0.6660. Next Query X1-X2: ['0.917077', '0.459697']...\n",
      "INFO: \n",
      "--- Processing Function F3 (D=3) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.6805\n",
      "INFO: Optimal EI found: 0.0229\n",
      "INFO: F3 (3D): f_best=-0.0200. Next Query X1-X3: ['0.528145', '0.578868', '0.510550']...\n",
      "INFO: \n",
      "--- Processing Function F4 (D=4) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -13.6857\n",
      "INFO: Optimal EI found: 1.8692\n",
      "INFO: F4 (4D): f_best=-2.9741. Next Query X1-X4: ['0.375246', '0.298707', '0.306354', '0.661866']...\n",
      "INFO: \n",
      "--- Processing Function F5 (D=4) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.9647\n",
      "INFO: Optimal EI found: 0.0000\n",
      "INFO: F5 (4D): f_best=4440.4809. Next Query X1-X4: ['0.444945', '0.803224', '0.025851', '0.939717']...\n",
      "INFO: \n",
      "--- Processing Function F6 (D=5) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -18.1027\n",
      "INFO: Optimal EI found: 0.0522\n",
      "INFO: F6 (5D): f_best=-0.7143. Next Query X1-X5: ['0.150753', '1.000000', '0.348153', '0.764860', '0.148911']...\n",
      "INFO: \n",
      "--- Processing Function F7 (D=6) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -22.3186\n",
      "INFO: Optimal EI found: 0.0277\n",
      "INFO: F7 (6D): f_best=1.6487. Next Query X1-X6: ['0.326546', '0.400548', '0.705139', '0.083355', '0.406493', '0.059994']...\n",
      "INFO: \n",
      "--- Processing Function F8 (D=8) ---\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -16.0542\n",
      "INFO: Optimal EI found: 0.2246\n",
      "INFO: F8 (8D): f_best=9.9951. Next Query X1-X8: ['0.000000', '0.994502', '0.072091', '0.887942', '0.661276', '0.366557', '0.407295', '0.000000']...\n",
      "INFO: \n",
      "**********************************************************************\n",
      "INFO: SUCCESS: Applying constraint (1.0 -> 0.999999) and saving FINAL queries for Week 7...\n",
      "INFO: File saved to: 'add_data/week07_clean_inputs.json'. This is the file to submit.\n",
      "INFO: **********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Union, Callable\n",
    "\n",
    "# Set up logging for cleaner output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# Suppress GPR numerical warnings and convergence warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# --- Configuration for Final Exploitation Phase (Week 7) ---\n",
    "DATA_FILE_PATH = 'bbo_master_w07.csv' # Input data file\n",
    "ADD_DATA_DIR = 'add_data'\n",
    "OUTPUT_FILE_PATH = os.path.join(ADD_DATA_DIR, 'week07_clean_inputs.json') # Output query file\n",
    "\n",
    "# Define the dimensions (D) for each function (F1 to F8)\n",
    "FUNCTION_DIMS = {\n",
    "    1: 2, 2: 2, 3: 3, 4: 4,\n",
    "    5: 4, 6: 5, 7: 6, 8: 8\n",
    "}\n",
    "\n",
    "# Strategy: Pure Exploitation for final round\n",
    "ACQUISITION_STRATEGIES = {\n",
    "    f_id: 'EI' for f_id in FUNCTION_DIMS.keys()\n",
    "}\n",
    "\n",
    "# --- Acquisition Function Definitions ---\n",
    "\n",
    "def expected_improvement(X_query: np.ndarray, gpr: GaussianProcessRegressor, Y_best: Union[float, None]) -> float:\n",
    "    \"\"\"\n",
    "    Expected Improvement (EI) acquisition function, formulated for MAXIMIZATION.\n",
    "    \n",
    "    Y_best must be the best known *maximum* value.\n",
    "    Returns the NEGATIVE EI, as we use scipy.optimize.minimize to find the maximum.\n",
    "    \"\"\"\n",
    "    if Y_best is None:\n",
    "        return 0.0 \n",
    "\n",
    "    # Predict mean (mu) and standard deviation (sigma)\n",
    "    X_query = np.atleast_2d(X_query)\n",
    "    # The GPR predicts based on the D-dimensional input, not the padded 8D array\n",
    "    mu, sigma = gpr.predict(X_query, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    \n",
    "    # Handle sigma close to zero (already sampled points)\n",
    "    if sigma < 1e-6:\n",
    "        return 0.0\n",
    "    \n",
    "    # Standard calculation of EI\n",
    "    # We use the correct formulation: EI = (mu - Y_best) * Phi(z) + sigma * phi(z)\n",
    "    z = (mu - Y_best) / sigma\n",
    "    \n",
    "    # Normalised CDF (c) = Phi(z) and PDF (p) = phi(z)\n",
    "    c = norm.cdf(z)\n",
    "    p = norm.pdf(z)\n",
    "    \n",
    "    # Expected Improvement formula\n",
    "    ei = (mu - Y_best) * c + sigma * p\n",
    "    \n",
    "    # Return the negative value to MAXIMIZE EI using a MINIMIZER\n",
    "    return -ei \n",
    "\n",
    "# --- Core BBO Functions ---\n",
    "\n",
    "def load_and_preprocess_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads the master CSV file, performs basic cleaning, and scales Y values.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"Data file not found at: {file_path}. Please ensure '{DATA_FILE_PATH}' is available.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    # Replace NaN with 0.0 for X columns (to handle padded dimensions from the master file)\n",
    "    x_cols = [f'X{i}' for i in range(1, 9)]\n",
    "    df[x_cols] = df[x_cols].fillna(0.0)\n",
    "    \n",
    "    # Scale Y to ensure positive values for GPR stability if Y can be heavily negative.\n",
    "    # We maintain the relative order (maximization target remains the same)\n",
    "    df['Y_Scaled'] = df['Y'] - df['Y'].min() + 1e-6\n",
    "    \n",
    "    return df\n",
    "\n",
    "def optimise_acquisition(\n",
    "    gpr: GaussianProcessRegressor, \n",
    "    D: int, \n",
    "    acquisition_func: Callable, \n",
    "    Y_best: Union[float, None] = None\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Minimizes the NEGATIVE acquisition function to find the next query point \n",
    "    that MAXIMIZES the acquisition. This optimization search is ONLY over D dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if acquisition_func == expected_improvement and Y_best is None:\n",
    "        raise ValueError(\"Y_best must be provided for Expected Improvement.\")\n",
    "        \n",
    "    # Define the objective function wrapper for the minimizer\n",
    "    target_func = lambda x: acquisition_func(x, gpr, Y_best)\n",
    "    \n",
    "    # Set bounds: [0, 1] for active dimensions\n",
    "    bounds_active = [(0, 1)] * D\n",
    "    \n",
    "    n_restarts = 10 \n",
    "    best_x_active = None\n",
    "    min_acq_value = np.inf \n",
    "    \n",
    "    for _ in range(n_restarts):\n",
    "        # Initial point x0 for the D active dimensions\n",
    "        x0_active = np.random.uniform(0, 1, D)\n",
    "        \n",
    "        # Use L-BFGS-B for bounded optimization\n",
    "        res = minimize(\n",
    "            fun=target_func, \n",
    "            x0=x0_active, \n",
    "            bounds=bounds_active, \n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success and res.fun < min_acq_value:\n",
    "            min_acq_value = res.fun\n",
    "            best_x_active = res.x\n",
    "            \n",
    "    if best_x_active is None:\n",
    "         # Fallback to a random point if optimisation failed\n",
    "         best_x_active = np.random.uniform(0, 1, D)\n",
    "    \n",
    "    # Combine the D-dimensional result with padded zeros to create the 8D query array\n",
    "    next_query_8d = np.concatenate([best_x_active, np.zeros(8 - D)])\n",
    "        \n",
    "    # Return the 8D query array and the maximum acquisition value (positive)\n",
    "    return next_query_8d, -min_acq_value\n",
    "\n",
    "def constrain_queries(queries: List[List[float]], epsilon: float = 1e-6) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    APPLIES THE CRITICAL CONSTRAINT: 0 <= x_i < 1.\n",
    "    Replaces any value of exactly 1.0 with 1.0 - epsilon.\n",
    "    \"\"\"\n",
    "    constrained_queries = []\n",
    "    for query in queries:\n",
    "        # Ensure x < 1.0 for all dimensions (0.0 padding is unaffected)\n",
    "        constrained_row = [x if x < 1.0 else (1.0 - epsilon) for x in query]\n",
    "        constrained_queries.append(constrained_row)\n",
    "    return constrained_queries\n",
    "\n",
    "def run_optimisation():\n",
    "    \"\"\"Main function to orchestrate the data loading, model training, and query generation.\"\"\"\n",
    "    df_master = load_and_preprocess_data(DATA_FILE_PATH)\n",
    "    if df_master.empty:\n",
    "        return\n",
    "        \n",
    "    all_queries = []\n",
    "    \n",
    "    for f_id, D in FUNCTION_DIMS.items():\n",
    "        logging.info(f\"\\n--- Processing Function F{f_id} (D={D}) ---\")\n",
    "        \n",
    "        # 1. Prepare Data for current function\n",
    "        df_func = df_master[df_master['Function ID'] == f_id].copy()\n",
    "        \n",
    "        # Only use the active dimensions X1 to X_D for training\n",
    "        x_cols = [f'X{i}' for i in range(1, D + 1)]\n",
    "        X_train = df_func[x_cols].values # X_train is correctly D-dimensional\n",
    "        Y_train = df_func['Y_Scaled'].values\n",
    "        \n",
    "        # 2. Train Gaussian Process Regressor (GPR)\n",
    "        # Using Matern kernel (nu=2.5) for general smoothness\n",
    "        kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(D), length_scale_bounds=(1e-3, 1e3), nu=2.5)\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, n_restarts_optimizer=10, normalize_y=True)\n",
    "        \n",
    "        try:\n",
    "            gpr.fit(X_train, Y_train)\n",
    "            logging.info(f\"GPR Model Trained. Log-Marginal-Likelihood: {gpr.log_marginal_likelihood():.4f}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error training GPR for F{f_id}: {e}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Optimise Acquisition Function (Expected Improvement for Week 7)\n",
    "        strategy_name = ACQUISITION_STRATEGIES[f_id]\n",
    "        acq_func = expected_improvement\n",
    "        \n",
    "        Y_best_scaled = np.max(Y_train) # Target is the maximum scaled Y\n",
    "        \n",
    "        # Optimise acquisition to find the next best query point\n",
    "        next_query_8d, optimal_value = optimise_acquisition(gpr, D, acq_func, Y_best_scaled)\n",
    "        \n",
    "        # 4. Format Output and store the 8D float array\n",
    "        all_queries.append([float(x) for x in next_query_8d])\n",
    "        \n",
    "        logging.info(f\"Optimal {strategy_name} found: {optimal_value:.4f}\")\n",
    "        logging.info(f\"F{f_id} ({D}D): f_best={df_func['Y'].max():.4f}. Next Query X1-X{D}: {[f'{x:.6f}' for x in next_query_8d[:D]]}...\")\n",
    "        \n",
    "    # 5. Apply the Constraint: 0 <= x_i < 1\n",
    "    all_queries_constrained = constrain_queries(all_queries, epsilon=1e-6)\n",
    "    \n",
    "    # 6. Save to JSON file\n",
    "    logging.info(\"\\n\" + \"*\" * 70)\n",
    "    logging.info(\"SUCCESS: Applying constraint (1.0 -> 0.999999) and saving FINAL queries for Week 7...\")\n",
    "    \n",
    "    if not os.path.exists(ADD_DATA_DIR):\n",
    "        os.makedirs(ADD_DATA_DIR)\n",
    "        \n",
    "    # Dump the constrained list of lists (8 functions, 8 inputs each)\n",
    "    output_data = [[f'{x:.6f}' for x in query] for query in all_queries_constrained]\n",
    "\n",
    "    with open(OUTPUT_FILE_PATH, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "        \n",
    "    logging.info(f\"File saved to: '{OUTPUT_FILE_PATH}'. This is the file to submit.\")\n",
    "    logging.info(\"*\" * 70)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_optimisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4424af-6a1c-4458-9992-332b2714eed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
