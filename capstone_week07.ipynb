{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f951f4-7a95-4353-b833-388bb7d26642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Import necessary components from scikit-learn for GPR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a3677e-da2f-4e74-ace6-3e5880a1c3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MASTER_FILE_PATH = 'bbo_master_w06.csv' # The master file updated after Week 6 results\n",
    "OUTPUT_DIR = 'add_data'\n",
    "OUTPUT_FILE_PATH = os.path.join(OUTPUT_DIR, 'week07_clean_inputs.json')\n",
    "# Function ID -> Dimension (D) mapping\n",
    "FUNCTION_DIMS: Dict[int, int] = {\n",
    "    1: 2, 2: 2, 3: 3, 4: 4, 5: 4, 6: 5, 7: 6, 8: 8\n",
    "}\n",
    "\n",
    "# Set up logging for cleaner output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# Suppress GPR numerical warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5521dfbc-1873-4e39-bea8-d8e55d1d4531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data_for_function(df: pd.DataFrame, func_id: int, D: int) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for a specific function, selects the correct X columns,\n",
    "    performs explicit type conversion and NaN removal for maximum robustness.\n",
    "    \"\"\"\n",
    "    df_func = df[df['Function ID'] == func_id].copy()\n",
    "    \n",
    "    # 1. Define the relevant columns for this function\n",
    "    x_cols = [f'X{i}' for i in range(1, D + 1)]\n",
    "    required_cols = x_cols + ['Y']\n",
    "    \n",
    "    # 2. Force type conversion: Convert all required columns to numeric, coercing any non-numeric \n",
    "    # value (like a blank or string) to a proper floating-point NaN.\n",
    "    for col in required_cols:\n",
    "        df_func[col] = pd.to_numeric(df_func[col], errors='coerce')\n",
    "\n",
    "    # 3. Drop rows with any NaN in the REQUIRED columns (X1...XD and Y)\n",
    "    X_Y_clean = df_func.dropna(subset=required_cols)\n",
    "    \n",
    "    X = X_Y_clean[x_cols].values\n",
    "    Y = X_Y_clean['Y'].values.reshape(-1, 1)\n",
    "\n",
    "    if X.shape[0] < 2:\n",
    "        logging.error(f\"Function F{func_id}: Not enough clean data points ({X.shape[0]}) to train GPR.\")\n",
    "        raise ValueError(\"Insufficient data points after cleaning.\")\n",
    "\n",
    "    # Find the best current maximum Y value\n",
    "    f_best = Y.max()\n",
    "    \n",
    "    logging.info(f\"Function F{func_id}: Loaded {X.shape[0]} clean points. Dimension D={D} enforced. f_best={f_best:.4f}\")\n",
    "    \n",
    "    return X, Y, f_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bea202a-1472-48ca-a679-eb5cbe26dc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expected_improvement(X_candidate: np.ndarray, gpr: GaussianProcessRegressor, f_best: float, xi: float = 0.01) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the Expected Improvement (EI) for a candidate point X_candidate.\n",
    "    Returns the negative EI, as 'minimize' is used for optimisation.\n",
    "    \"\"\"\n",
    "    X_candidate = X_candidate.reshape(1, -1)\n",
    "    \n",
    "    mu, sigma = gpr.predict(X_candidate, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "\n",
    "    if np.ndim(sigma) == 0:\n",
    "        sigma = np.array([sigma])\n",
    "\n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - f_best - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        # Set EI to 0 where the variance is extremely small (i.e., already sampled)\n",
    "        ei[sigma < 1e-10] = 0.0\n",
    "        \n",
    "    return -ei.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2fe681-9dd6-49ab-816b-d73114b09dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def propose_next_query(gpr: GaussianProcessRegressor, f_best: float, D: int, num_restarts: int = 30) -> List[float]:\n",
    "    \"\"\"\n",
    "    Maximises the Expected Improvement acquisition function by minimising the negative EI.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_ei = -np.inf\n",
    "    best_x = None\n",
    "    \n",
    "    # Use Bounds object for 'L-BFGS-B'\n",
    "    bounds = Bounds(0.0, 1.0)\n",
    "    \n",
    "    for _ in range(num_restarts):\n",
    "        # Initial guess must be within bounds\n",
    "        x0 = np.random.uniform(0.0, 1.0, size=D)\n",
    "        \n",
    "        result = minimize(\n",
    "            fun=expected_improvement,\n",
    "            x0=x0,\n",
    "            args=(gpr, f_best, 0.01),\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds\n",
    "        )\n",
    "        \n",
    "        # result.fun is the minimum negative EI, so -result.fun is the maximum positive EI\n",
    "        if -result.fun > best_ei:\n",
    "            best_ei = -result.fun\n",
    "            # Convert the numpy array result to a standard Python list\n",
    "            best_x = result.x.tolist()\n",
    "    \n",
    "    logging.info(f\"Optimal EI found: {best_ei:.4f}\")\n",
    "\n",
    "    if best_x is None:\n",
    "        logging.warning(f\"Optimisation failed. Returning random query.\")\n",
    "        best_x = np.random.uniform(0.0, 1.0, size=D).tolist()\n",
    "    \n",
    "    # Ensure all values are clamped between 0.0 and 1.0 (though L-BFGS-B with Bounds should handle this)\n",
    "    return [max(0.0, min(1.0, val)) for val in best_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea14632c-df6f-4b56-b293-6b1272bffc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_optimisation() -> None:\n",
    "    \"\"\"Main function to run the BBO query generation process.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(MASTER_FILE_PATH):\n",
    "        logging.error(f\"Master file not found at: {MASTER_FILE_PATH}\")\n",
    "        return\n",
    "\n",
    "    df_master = pd.read_csv(MASTER_FILE_PATH)\n",
    "    \n",
    "    all_queries = []\n",
    "    \n",
    "    for func_id, D in FUNCTION_DIMS.items():\n",
    "        logging.info(f\"\\n--- Processing Function F{func_id} ({D}D) ---\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Clean and filter data\n",
    "            X, Y, f_best_raw = clean_data_for_function(df_master, func_id, D)\n",
    "            \n",
    "            # 2. Scale Y data (standard practice for GPR)\n",
    "            scaler_y = StandardScaler()\n",
    "            Y_scaled = scaler_y.fit_transform(Y)\n",
    "            f_best_scaled = scaler_y.transform([[f_best_raw]])[0, 0]\n",
    "            \n",
    "            # 3. Define the kernel (fixed for version compatibility and robustness)\n",
    "            kernel = (\n",
    "                C(1.0, constant_value_bounds=(1e-3, 1e3)) * RBF(length_scale=np.ones(D), length_scale_bounds=(1e-3, 1e3)) + \n",
    "                WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-7, 1e-1))\n",
    "            )\n",
    "            \n",
    "            # 4. Train the GPR model\n",
    "            gpr = GaussianProcessRegressor(\n",
    "                kernel=kernel, \n",
    "                alpha=0.0, \n",
    "                n_restarts_optimizer=15\n",
    "            )\n",
    "            gpr.fit(X, Y_scaled.flatten())\n",
    "            \n",
    "            logging.info(f\"GPR Model Trained. Log-Marginal-Likelihood: {gpr.log_marginal_likelihood_value_:.4f}\")\n",
    "            \n",
    "            # 5. Propose next query using Expected Improvement\n",
    "            next_X = propose_next_query(gpr, f_best_scaled, D, num_restarts=30)\n",
    "            \n",
    "            # 6. Format and pad the query for the final JSON submission\n",
    "            padded_query_raw = next_X + [0.0] * (8 - len(next_X))\n",
    "            \n",
    "            # Apply required rounding to 6 decimal places for final output\n",
    "            # This ensures they are numerical floats with the correct precision.\n",
    "            padded_query = [round(val, 6) for val in padded_query_raw]\n",
    "\n",
    "            all_queries.append(padded_query)\n",
    "            \n",
    "            logging.info(f\"F{func_id} Proposed Query (D={D}): {padded_query[:D]} (Rounded to 6 DP)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"FATAL ERROR processing Function F{func_id}: {e}. Returning random query.\")\n",
    "            D_error = FUNCTION_DIMS.get(func_id)\n",
    "            if D_error:\n",
    "                # Generate and round a random query on error\n",
    "                next_X_random = np.random.uniform(0.0, 1.0, size=D_error).tolist()\n",
    "                padded_query_raw = next_X_random + [0.0] * (8 - D_error)\n",
    "                padded_query = [round(val, 6) for val in padded_query_raw]\n",
    "            else:\n",
    "                padded_query = [0.0] * 8 \n",
    "\n",
    "            all_queries.append(padded_query)\n",
    "\n",
    "\n",
    "    # --- Final Output Generation (JSON) ---\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    try:\n",
    "        # Use simple json.dump, which correctly writes Python floats as JSON numbers\n",
    "        with open(OUTPUT_FILE_PATH, 'w') as f:\n",
    "            json.dump(all_queries, f, indent=2)\n",
    "            \n",
    "        logging.info(\"\\n--------------------------------------------------\")\n",
    "        logging.info(f\"SUCCESS: Generated {len(all_queries)} FINAL queries for Week 7.\")\n",
    "        logging.info(f\"File saved to: '{OUTPUT_FILE_PATH}'. This is the file to submit.\")\n",
    "        logging.info(\"--------------------------------------------------\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eec4078-c849-462c-9bae-06e54c7858bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "--- Processing Function F1 (2D) ---\n",
      "INFO: Function F1: Loaded 14 clean points. Dimension D=2 enforced. f_best=0.1744\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -16.3722\n",
      "INFO: Optimal EI found: 0.0002\n",
      "INFO: F1 Proposed Query (D=2): [0.736739, 1.0] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F2 (2D) ---\n",
      "INFO: Function F2: Loaded 13 clean points. Dimension D=2 enforced. f_best=0.6660\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.1975\n",
      "INFO: Optimal EI found: 0.0504\n",
      "INFO: F2 Proposed Query (D=2): [0.702802, 0.967778] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F3 (3D) ---\n",
      "INFO: Function F3: Loaded 12 clean points. Dimension D=3 enforced. f_best=-0.0200\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -10.6301\n",
      "INFO: Optimal EI found: 0.2364\n",
      "INFO: F3 Proposed Query (D=3): [0.051259, 0.0, 0.61341] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F4 (4D) ---\n",
      "INFO: Function F4: Loaded 13 clean points. Dimension D=4 enforced. f_best=-2.9741\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.9664\n",
      "INFO: Optimal EI found: 0.0691\n",
      "INFO: F4 Proposed Query (D=4): [0.367805, 0.616536, 0.155114, 0.09472] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F5 (4D) ---\n",
      "INFO: Function F5: Loaded 13 clean points. Dimension D=4 enforced. f_best=1091.3153\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.6705\n",
      "INFO: Optimal EI found: 0.6699\n",
      "INFO: F5 Proposed Query (D=4): [0.291309, 0.880839, 1.0, 1.0] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F6 (5D) ---\n",
      "INFO: Function F6: Loaded 13 clean points. Dimension D=5 enforced. f_best=-0.7143\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -15.5858\n",
      "INFO: Optimal EI found: 0.2620\n",
      "INFO: F6 Proposed Query (D=5): [0.009158, 0.038068, 0.820763, 0.480254, 0.0] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F7 (6D) ---\n",
      "INFO: Function F7: Loaded 13 clean points. Dimension D=6 enforced. f_best=1.6487\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -16.3862\n",
      "INFO: Optimal EI found: 0.0950\n",
      "INFO: F7 Proposed Query (D=6): [0.357755, 0.636365, 0.62316, 0.404505, 0.665254, 0.451236] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--- Processing Function F8 (8D) ---\n",
      "INFO: Function F8: Loaded 11 clean points. Dimension D=8 enforced. f_best=9.9951\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -12.3258\n",
      "INFO: Optimal EI found: 0.1410\n",
      "INFO: F8 Proposed Query (D=8): [0.048509, 0.845466, 0.836123, 0.922872, 0.553865, 1.0, 1.0, 1.0] (Rounded to 6 DP)\n",
      "INFO: \n",
      "--------------------------------------------------\n",
      "INFO: SUCCESS: Generated 8 FINAL queries for Week 7.\n",
      "INFO: File saved to: 'add_data/week07_clean_inputs.json'. This is the file to submit.\n",
      "INFO: --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_optimisation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
