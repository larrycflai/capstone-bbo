{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a13fa8cf-9f5a-4079-8343-af99826b4266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Capstone_week02.ipynb\n",
    "# Generates 8 new queries (one for each function) for Week 2 of the BBO challenge.\n",
    "# Strategy is adapted based on Week 1 results:\n",
    "# F4 & F6 (poor results) swapped to UCB (Explore).\n",
    "# F5 (excellent result) swapped to EI (Exploit).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress sklearn warnings during optimisation\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7433adc-3519-4849-af5e-9bf0d8ed92f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "\n",
    "# NOTE: This file name MUST match the output of data merger script.\n",
    "MASTER_DATA_FILE = 'bbo_master_w02.csv'\n",
    "\n",
    "# Output file for the new queries\n",
    "QUERIES_OUTPUT_FILE = 'week02_queries.csv'\n",
    "\n",
    "# Define the acquisition function strategy:\n",
    "# Alternate between EI and UCB to balance exploitation and exploration.\n",
    "# with adjustments based on Week 1 performance.\n",
    "ACQUISITION_STRATEGY = {\n",
    "    # F1 (2D, simpler, low-D) -> Exploit (EI)\n",
    "    1: 'EI',\n",
    "    # F2 (2D, simpler, low-D) -> Exploit (EI)\n",
    "    2: 'EI',\n",
    "    # F3 (3D, moderate) -> Explore (UCB)\n",
    "    3: 'UCB',\n",
    "    # --- based on Week 1 results: F4 is poor, needs EXPLORATION.\n",
    "    # F5 is great, needs EXPLOITATION. ---\n",
    "    # F4 (4D, moderate) -> Explore (UCB)\n",
    "    4: 'UCB',\n",
    "    # F5 (4D, moderate) -> Exploit (EI)\n",
    "    5: 'EI',\n",
    "    # F6 (5D, poor result: -1.02, needs aggressinve EXPLORATION)\n",
    "    6: 'UCB',\n",
    "    # F7 (6D, higher, low result: 0.54, continue EXPLORATION)\n",
    "    7: 'UCB',\n",
    "    # F8 (8D, high-D, good result: 9.89, continue EXPLORATION due to high D)\n",
    "    8: 'UCB',\n",
    "}\n",
    "\n",
    "# UCB exploration parameter (kappa):\n",
    "# Higher kappa encourages more exploration (searching uncertain areas).\n",
    "# Use a higher kappa for high-D functions where uncertainty is vast.\n",
    "\n",
    "UCB_KAPPA = {\n",
    "    'low_d': 1.5,  # For F1, F2\n",
    "    'high_d': 2.5  # For F3-F8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cbdce93c-90c3-4d0c-b99f-9d9470fb1780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 2. ACQUISITION FUNCTIONS ---\n",
    "\n",
    "def expected_improvement(X, model, current_best_y):\n",
    "    \"\"\"\n",
    "    Expected Improvement (EI) for exploitation.\n",
    "    It measures the expected gain from sampling X.\n",
    "    \"\"\"\n",
    "    mu, sigma = model.predict(X, return_std=True)\n",
    "   \n",
    "    # Handle zero standard deviation to prevent errors\n",
    "    with np.errstate(divide='ignore'):\n",
    "        Z = (current_best_y - mu) / sigma\n",
    "        # Calculate EI\n",
    "        ei = (current_best_y - mu) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0  # if uncertainty is zero, EI is zero\n",
    "        \n",
    "    # try to *maximise* EI, so return the positive value\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6dacc3a-b29c-46cc-b978-c9b9f3b92b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upper_confidence_bound(X, model, kappa):\n",
    "    \"\"\"\n",
    "    Upper Confidence Bound (UCB) for exploration\n",
    "    It balances mean prediction (mu) and uncertainty (sigma).\n",
    "    \"\"\"\n",
    "    mu, sigma = model.predict(X, return_std=True)\n",
    "    \n",
    "    # UCB = Mean + Kappa * Standard Deviation\n",
    "    # Higher kappa encourages more exploration of uncertain areas.\n",
    "    return mu + kappa * sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50ca8273-a790-4c14-b9ff-af2d1c772b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def next_query_point(acq_func, model, bounds, current_best_y, kappa=None, n_random_samples=10000):\n",
    "    \"\"\"\n",
    "    Uses random search to find the point (X) that maximises the acquisition function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Generate many random candidate points across the search space [0, 1]\n",
    "    # n_dims is the no. of input dimensions for the function (e.g., 2 for F1, 8 for F8)\n",
    "    n_dims = bounds.shape[0]\n",
    "    candidate_x = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_random_samples, n_dims))\n",
    "    \n",
    "    # 2. Evaluate the acquisition function for all candidate points\n",
    "    if acq_func == 'EI':\n",
    "        scores = expected_improvement(candidate_x, model, current_best_y)\n",
    "    elif acq_func == 'UCB':\n",
    "        scores = upper_confidence_bound(candidate_x, model, kappa)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown acquisition function: {acq_func}\")\n",
    "        \n",
    "    # 3. Find the candidate point that yields the maximum score\n",
    "    best_x = candidate_x[np.argmax(scores)]\n",
    "    \n",
    "    return best_x.reshape(1, -1)  # Return as a 2D array (1 row, N columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60760bcb-a4b2-4ff1-b30a-ed1ca0d7158f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 3. MAIN FUNCTION ---\n",
    "\n",
    "def generate_week02_queries():\n",
    "    \"\"\"\n",
    "    Loads data, trains GP models, and generates the 8 new queries.\n",
    "    \"\"\"\n",
    "    print(f\"Loading master data from {MASTER_DATA_FILE}...\")\n",
    "    if not os.path.exists(MASTER_DATA_FILE):\n",
    "        print(f\"Error: {MASTER_DATA_FILE} not found. Ensure the data merger script was run.\")\n",
    "        return\n",
    "    \n",
    "    # Set up the base DataFrame\n",
    "    df_master = pd.read_csv(MASTER_DATA_FILE)\n",
    "    x_cols = [f'X{i}' for i in range(1, 9)]\n",
    "    \n",
    "    # Store all generated rows in a list of dictionaries\n",
    "    all_new_rows = []\n",
    "    \n",
    "    # Loop through all 8 functions\n",
    "    for func_id in range(1, 9):\n",
    "        # 3.1 Data Filtering and Preparation\n",
    "        df_func = df_master[df_master['Function ID'] == func_id].copy()\n",
    "        \n",
    "        # Determine the no. of dimensions (e.g., 2 for F1, 8 for F8)\n",
    "        # Count non-NaN X columns\n",
    "        n_dims = 0\n",
    "        for col in x_cols:\n",
    "            # The dimension is the index of the last X column that has non-NaN values\n",
    "            if df_func[col].notna().any():\n",
    "                n_dims += 1\n",
    "            else:\n",
    "                # Since X columns are sequential (X1, X2, ...), we can stop\n",
    "                # as soon as hitting a column that is entirely NaN for this function.\n",
    "                break\n",
    "        \n",
    "        if n_dims == 0:\n",
    "            print(f\"Skipping F{func_id}: No valid data points found.\")\n",
    "            continue\n",
    "        \n",
    "        # Isolate the relevant X (inputs) and Y (outputs)\n",
    "        X = df_func[x_cols[:n_dims]].values\n",
    "        Y = df_func['Y'].values.reshape(-1, 1)  # Reshape Y to be 2D\n",
    "        \n",
    "        # Current best observation (for EI) - to MAXIMISE Y\n",
    "        current_best_y = Y.max()\n",
    "        \n",
    "        # The search space bounds are always [0, 1] for all dimensions\n",
    "        bounds = np.array([[0.0, 1.0]] * n_dims)\n",
    "        \n",
    "        # 3.2 Model Training\n",
    "        # Use a Matern kernel, which is highly flexible for BBO\n",
    "        kernel = Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=2.5)\n",
    "        model = GaussianProcessRegressor(\n",
    "            kernel = kernel,\n",
    "            alpha = 1e-6,  # Small noise term for numerical stability\n",
    "            n_restarts_optimizer=20,\n",
    "            normalize_y = True  # Essential for robust GP performance\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            model.fit(X, Y)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fitting GP for F{func_id}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        # 3.3 Acquisition Function Selection and Parameter Setup\n",
    "        acq_func = ACQUISITION_STRATEGY[func_id]\n",
    "        \n",
    "        if acq_func == 'UCB':\n",
    "            # Use .get() for safe dictionary access, providing defaults to prevent KeyError\n",
    "            high_d_kappa = UCB_KAPPA.get('high_d', 2.5)\n",
    "            low_d_kappa = UCB_KAPPA.get('low_d', 1.5)\n",
    "            kappa_val = high_d_kappa if n_dims > 2 else low_d_kappa\n",
    "            print(f\"F{func_id} ({n_dims}D): Strategy = UCB (Kappa = {kappa_val})\")\n",
    "        else:\n",
    "            kappa_val = None\n",
    "            print(f\"F{func_id} ({n_dims}D): Strategy = EI (Current Best Y={current_best_y:.4f})\")\n",
    "            \n",
    "        # 3.4 Query Generation\n",
    "        new_x_array = next_query_point(\n",
    "            acq_func = acq_func,\n",
    "            model = model,\n",
    "            bounds = bounds,\n",
    "            current_best_y = current_best_y,\n",
    "            kappa = kappa_val\n",
    "        )\n",
    "        \n",
    "        # 3.5 Format and Append Result\n",
    "        new_row = {'Function ID': func_id}  # Y is NaN until submitted/returned\n",
    "        \n",
    "        # Initialise all X columns to NaN\n",
    "        for col in x_cols:\n",
    "            new_row[col] = np.nan\n",
    "        \n",
    "        # Convert the generated coordinates array to a flat list for clean assignment\n",
    "        generated_coords = new_x_array.flatten()      \n",
    "        \n",
    "        # Overwrite the relevant X values with the generated query\n",
    "        # Iterates over the generated_coords list\n",
    "        for i in range(n_dims):\n",
    "            col_name = f'X{i+1}'\n",
    "            # Ensure the coordinate is a standard Python float\n",
    "            new_row[col_name] = float(generated_coords[i])\n",
    "            \n",
    "        # Append the dictionary to the list\n",
    "        all_new_rows.append(new_row)\n",
    "            \n",
    "        \n",
    "    # 3.6 Create Final DataFrame, Save, and Print the Queries\n",
    "    \n",
    "    # Define the exact columns required for the submission file\n",
    "    submission_cols = ['Function ID'] + [f'X{i}' for i in range(1, 9)]\n",
    "    \n",
    "    # Create the final DataFrame using the list of rows and select/reorder columns\n",
    "    df_queries = pd.DataFrame(all_new_rows)\n",
    "    df_queries = df_queries[submission_cols]\n",
    "    \n",
    "    # Round the X columns to 6 dec. places for the submission format.\n",
    "    x_cols_to_round = [col for col in submission_cols if col.startswith('X')]\n",
    "    df_queries[x_cols_to_round] = df_queries[x_cols_to_round].round(6)\n",
    "    \n",
    "    # Save the final queries\n",
    "    df_queries.to_csv(QUERIES_OUTPUT_FILE, index=False)\n",
    "    \n",
    "    # Print the queries to the console \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"| GENERATED QUERIES FOR WEEK 2 ({QUERIES_OUTPUT_FILE}) |\")\n",
    "    print(\"=\" * 60)\n",
    "    print(df_queries.to_string(index=False))\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"SUCCESS: Generated {len(df_queries)} queries for Week 2.\")\n",
    "    print(f\"File saved as '{QUERIES_OUTPUT_FILE}'.\")\n",
    "    print(\"This file contains the X inputs to submit to the Capstone portal.\")\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be239fd0-eae2-4f89-a9bd-bff97e123c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master data from bbo_master_w02.csv...\n",
      "F1 (2D): Strategy = EI (Current Best Y=0.0000)\n",
      "F2 (2D): Strategy = EI (Current Best Y=0.6112)\n",
      "F3 (3D): Strategy = UCB (Kappa = 2.5)\n",
      "F4 (4D): Strategy = UCB (Kappa = 2.5)\n",
      "F5 (4D): Strategy = EI (Current Best Y=1091.3153)\n",
      "F6 (5D): Strategy = UCB (Kappa = 2.5)\n",
      "F7 (6D): Strategy = UCB (Kappa = 2.5)\n",
      "F8 (8D): Strategy = UCB (Kappa = 2.5)\n",
      "\n",
      "============================================================\n",
      "| GENERATED QUERIES FOR WEEK 2 (week02_queries.csv) |\n",
      "============================================================\n",
      " Function ID       X1       X2       X3       X4       X5       X6      X7       X8\n",
      "           1 0.630822 0.662337      NaN      NaN      NaN      NaN     NaN      NaN\n",
      "           2 0.154270 0.343620      NaN      NaN      NaN      NaN     NaN      NaN\n",
      "           3 0.802457 0.736185 0.510802      NaN      NaN      NaN     NaN      NaN\n",
      "           4 0.371967 0.308509 0.271705 0.299497      NaN      NaN     NaN      NaN\n",
      "           5 0.317247 0.690020 0.262847 0.360195      NaN      NaN     NaN      NaN\n",
      "           6 0.691590 0.163316 0.826321 0.658325 0.024349      NaN     NaN      NaN\n",
      "           7 0.126848 0.488881 0.177645 0.336104 0.377780 0.643095     NaN      NaN\n",
      "           8 0.148162 0.138482 0.108206 0.709595 0.743266 0.027662 0.21235 0.082593\n",
      "============================================================\n",
      "\n",
      "--------------------------------------------------\n",
      "SUCCESS: Generated 8 queries for Week 2.\n",
      "File saved as 'week02_queries.csv'.\n",
      "This file contains the X inputs to submit to the Capstone portal.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    generate_week02_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520557b-c2af-4292-a032-cba2f2b6d57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6f83b-4958-4f7c-acf9-25d7f4daf8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
