{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7d0cbcb-44f0-4954-87ab-14aaf61c4128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Import necessary components from scikit-learn for GPR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ba3e3d-2583-4c6b-be8b-e7407c9afef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration for Balanced Refinement Phase (Week 4) ---\n",
    "DATA_FILE_PATH = 'bbo_master_w04.csv' # Assumes your complete data is named this\n",
    "OUTPUT_JSON_FILE = 'week04_queries.json'\n",
    "X_COLUMNS = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']\n",
    "DOMAIN_BOUNDS = [(0.0, 1.0) for _ in range(8)]\n",
    "N_INITIAL_SAMPLES = 100 # Number of random starting points for optimisation\n",
    "# XI = 0.01 provides a good balance between exploitation and exploration for this phase.\n",
    "XI = 0.01 \n",
    "# Output rounded to 6 decimal places\n",
    "ROUNDING_PRECISION = 6\n",
    "\n",
    "# Enforce strict [0, 1) constraint.\n",
    "UPPER_BOUND_REPLACEMENT = 0.999999\n",
    "\n",
    "# Suppress convergence warnings from GPR kernel optimization for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set up logging for cleaner output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08b52f13-35f2-4060-b99c-5271c18230ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_for_function(func_id: int, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "    \"\"\"Filters the master dataframe for a specific function ID and extracts X and Y arrays.\"\"\"\n",
    "    logging.info(f\"--- Processing Function F{func_id} ---\")\n",
    "    \n",
    "    # Filter data for the specific function ID\n",
    "    df_func = df[df['Function ID'] == func_id].copy()\n",
    "    \n",
    "    # Determine dimensionality (D) based on non-NaN X columns for the function\n",
    "    X_temp = df_func[X_COLUMNS].to_numpy()\n",
    "    D = np.sum(~np.isnan(X_temp[0])) if X_temp.size > 0 else 0\n",
    "    \n",
    "    if D == 0:\n",
    "        logging.error(f\"No data or dimensionality for F{func_id}. Skipping.\")\n",
    "        return np.array([]), np.array([]), 0\n",
    "        \n",
    "    # Extract X (only up to D dimensions) and Y\n",
    "    X = df_func[X_COLUMNS[:D]].to_numpy()\n",
    "    Y = df_func['Y'].to_numpy()\n",
    "    \n",
    "    logging.info(f\"Data points for F{func_id}: {len(X)}. Dimensionality (D): {D}.\")\n",
    "    \n",
    "    # CRITICAL: Get the best observed MAXIMUM (Y_max) from the entire history\n",
    "    y_max = Y.max()\n",
    "    logging.info(f\"Current historical Y_max for F{func_id}: {y_max:.5f}\")\n",
    "    \n",
    "    return X, Y, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4f2cfa1-c841-46df-ad9c-59d381a9d125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expected_improvement(X_new: np.ndarray, GPR: GaussianProcessRegressor, y_max: float, xi: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the negative Expected Improvement (EI) for minimisation.\n",
    "    We return -EI because scipy.optimize.minimize seeks to minimise the function.\n",
    "    \"\"\"\n",
    "    X_new = X_new.reshape(1, -1)\n",
    "    \n",
    "    # Predict mean (mu) and standard deviation (sigma) at the new point\n",
    "    mu, sigma = GPR.predict(X_new, return_std=True)\n",
    "    \n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    \n",
    "    if sigma == 0.0:\n",
    "        return -0.0\n",
    "    \n",
    "    # Calculate Z score\n",
    "    Z = (mu - y_max - xi) / sigma\n",
    "    \n",
    "    # Expected Improvement formula: E[I] = (mu - y_max - xi) * Phi(Z) + sigma * phi(Z)\n",
    "    EI = (mu - y_max - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    \n",
    "    # Return negative EI for minimisation\n",
    "    return -EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6effb0ed-430f-4933-8850-c3956bf9d821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def propose_next_query(GPR: GaussianProcessRegressor, X: np.ndarray, Y: np.ndarray, D: int, xi: float) -> List[float]:\n",
    "    \"\"\"Finds the query point that maximises the Expected Improvement (EI).\"\"\"\n",
    "    y_max = Y.max()\n",
    "    bounds = DOMAIN_BOUNDS[:D]\n",
    "    \n",
    "    neg_ei_func = lambda x: expected_improvement(x, GPR, y_max, xi=xi)\n",
    "    \n",
    "    best_ei = np.inf\n",
    "    best_x = None\n",
    "    \n",
    "    # Use multiple random restarts to find the global minimum of -EI\n",
    "    for _ in range(N_INITIAL_SAMPLES):\n",
    "        # Generate random initial point within bounds [0, 1]\n",
    "        x0 = np.random.uniform(0.0, 1.0, size=D)\n",
    "        \n",
    "        # Use L-BFGS-B, a bounded minimisation algorithm\n",
    "        res = minimize(neg_ei_func, x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success and res.fun < best_ei:\n",
    "            best_ei = res.fun\n",
    "            best_x = res.x\n",
    "            \n",
    "    if best_x is None:\n",
    "        logging.warning(\"Optimisation failed; picking random point as fallback.\")\n",
    "        return np.random.uniform(0.0, 1.0, size=D).tolist()\n",
    "    \n",
    "    # Ensure the result is clamped to [0.0, 1.0]\n",
    "    final_x = np.clip(best_x, 0.0, 1.0).tolist()\n",
    "    \n",
    "    logging.info(f\"Optimised Query found with EI: {-best_ei:.5f}\")\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f88ac034-c722-482d-8f68-e7a1b571b851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_gpr_and_propose(func_id: int, X: np.ndarray, Y: np.ndarray, D: int, xi: float) -> List[float]:\n",
    "    \"\"\"Trains a GPR model and proposes the next query point for a given function.\"\"\"\n",
    "    if D == 0 or len(X) == 0:\n",
    "        return [0.0] * D\n",
    "        \n",
    "    # Define the RBF Kernel with hyperparameter bounds\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(np.ones(D), (1e-2, 1e2))\n",
    "    \n",
    "    GPR = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6, # Small noise level (regularisation)\n",
    "        n_restarts_optimizer=20, \n",
    "        normalize_y=True # Important for robust scaling\n",
    "    )\n",
    "    \n",
    "    # Train the GPR model\n",
    "    GPR.fit(X, Y)\n",
    "    \n",
    "    # Propose the next point by maximising EI\n",
    "    next_query = propose_next_query(GPR, X, Y, D, xi)\n",
    "    \n",
    "    return next_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5514c1f1-c186-4616-9109-b25738abaa52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to orchestrate the Bayesian Optimisation process for all 8 functions.\"\"\"\n",
    "    logging.info(f\"Loading master data from: {DATA_FILE_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_FILE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"ERROR: Master data file not found at {DATA_FILE_PATH}. Please ensure it exists.\")\n",
    "        return\n",
    "    \n",
    "    all_queries: List[List[float]] = []\n",
    "    \n",
    "    # Iterate through Function IDs 1 to 8\n",
    "    for func_id in range(1, 9):\n",
    "        X, Y, D = get_data_for_function(func_id, df)\n",
    "        \n",
    "        if D == 0 or len(X) == 0:\n",
    "            all_queries.append([0.0] * 8)\n",
    "            continue\n",
    "        \n",
    "        # Train GPR and get the optimal next query point\n",
    "        query_x_d = train_gpr_and_propose(func_id, X, Y, D, XI)\n",
    "        \n",
    "        # 1. Round the D-dimensional query\n",
    "        rounded_query_x_d = [round(x, ROUNDING_PRECISION) for x in query_x_d]\n",
    "\n",
    "        # 2. Apply the [0, 1) constraint: replace 1.0 with 0.999999\n",
    "        query_x_clean = [\n",
    "            UPPER_BOUND_REPLACEMENT if x >= 1.0 else x\n",
    "            for x in rounded_query_x_d\n",
    "        ]\n",
    "        \n",
    "        # Pad the cleaned query to 8 dimensions with 0.0s\n",
    "        query_x_8d = query_x_clean + [0.0] * (8 - D)\n",
    "        all_queries.append(query_x_8d)\n",
    "        \n",
    "        logging.info(f\"F{func_id} Query ({D}D): {query_x_d}\")\n",
    "    \n",
    "    # Output the final 8-dimensional queries as a JSON file\n",
    "    logging.info(\"\\n--- Final Queries JSON ---\")\n",
    "    logging.info(json.dumps(all_queries, indent=2))\n",
    "    logging.info(\"----------------------------------\")\n",
    "    \n",
    "    # Save the output to a JSON file\n",
    "    with open(OUTPUT_JSON_FILE, 'w') as f:\n",
    "        json.dump(all_queries, f, indent=2)\n",
    "    \n",
    "    logging.info(f\"\\nINFO: Successfully generated 8 new queries. Saved to {OUTPUT_JSON_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3817778c-fb51-441c-8fd7-6ad4a5b48352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading master data from: bbo_master_w04.csv\n",
      "INFO: --- Processing Function F1 ---\n",
      "INFO: Data points for F1: 13. Dimensionality (D): 2.\n",
      "INFO: Current historical Y_max for F1: 0.06897\n",
      "INFO: Optimised Query found with EI: 0.00000\n",
      "INFO: F1 Query (2D): [0.5987146659727064, 0.6313764532646933]\n",
      "INFO: --- Processing Function F2 ---\n",
      "INFO: Data points for F2: 13. Dimensionality (D): 2.\n",
      "INFO: Current historical Y_max for F2: 0.61121\n",
      "INFO: Optimised Query found with EI: 0.03716\n",
      "INFO: F2 Query (2D): [0.6845728421667862, 1.0]\n",
      "INFO: --- Processing Function F3 ---\n",
      "INFO: Data points for F3: 13. Dimensionality (D): 3.\n",
      "INFO: Current historical Y_max for F3: -0.01996\n",
      "INFO: Optimised Query found with EI: 0.01444\n",
      "INFO: F3 Query (3D): [0.963787576903963, 3.3384862084158358e-18, 0.0]\n",
      "INFO: --- Processing Function F4 ---\n",
      "INFO: Data points for F4: 13. Dimensionality (D): 4.\n",
      "INFO: Current historical Y_max for F4: -2.97407\n",
      "INFO: Optimised Query found with EI: 0.84919\n",
      "INFO: F4 Query (4D): [0.2616533363434189, 0.44442293059760085, 0.2929780933348977, 0.022572993848140703]\n",
      "INFO: --- Processing Function F5 ---\n",
      "INFO: Data points for F5: 13. Dimensionality (D): 4.\n",
      "INFO: Current historical Y_max for F5: 1091.31526\n",
      "INFO: Optimised Query found with EI: 329.15257\n",
      "INFO: F5 Query (4D): [0.0, 1.0, 1.0, 1.0]\n",
      "INFO: --- Processing Function F6 ---\n",
      "INFO: Data points for F6: 13. Dimensionality (D): 5.\n",
      "INFO: Current historical Y_max for F6: -0.71426\n",
      "INFO: Optimised Query found with EI: 0.06664\n",
      "INFO: F6 Query (5D): [0.6276180613953299, 0.16276099485053072, 0.8432648282851476, 0.6810252294664488, 0.278627969876682]\n",
      "INFO: --- Processing Function F7 ---\n",
      "INFO: Data points for F7: 13. Dimensionality (D): 6.\n",
      "INFO: Current historical Y_max for F7: 1.64873\n",
      "INFO: Optimised Query found with EI: 0.13147\n",
      "INFO: F7 Query (6D): [0.5991750412448963, 0.046890484277430845, 0.7391905190570393, 0.46013855238284784, 0.6384190076132694, 0.3441056584954529]\n",
      "INFO: --- Processing Function F8 ---\n",
      "INFO: Data points for F8: 13. Dimensionality (D): 8.\n",
      "INFO: Current historical Y_max for F8: 9.99512\n",
      "INFO: Optimised Query found with EI: 2.66816\n",
      "INFO: F8 Query (8D): [0.0, 0.0, 0.07548211743565114, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "INFO: \n",
      "--- Final Queries JSON ---\n",
      "INFO: [\n",
      "  [\n",
      "    0.598715,\n",
      "    0.631376,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.684573,\n",
      "    0.999999,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.963788,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.261653,\n",
      "    0.444423,\n",
      "    0.292978,\n",
      "    0.022573,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.0,\n",
      "    0.999999,\n",
      "    0.999999,\n",
      "    0.999999,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.627618,\n",
      "    0.162761,\n",
      "    0.843265,\n",
      "    0.681025,\n",
      "    0.278628,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.599175,\n",
      "    0.04689,\n",
      "    0.739191,\n",
      "    0.460139,\n",
      "    0.638419,\n",
      "    0.344106,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  [\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.075482,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.999999\n",
      "  ]\n",
      "]\n",
      "INFO: ----------------------------------\n",
      "INFO: \n",
      "INFO: Successfully generated 8 new queries. Saved to week04_queries.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc358f-298f-43a9-867a-31e921284329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
