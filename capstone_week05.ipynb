{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b718af2-0255-41bc-b72e-f95b1fadb761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Import necessary components from scikit-learn for GPR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "368312f9-7760-46ef-9dc5-c3ab76667e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress Convergence Warnings from optimiser for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Set up logging for clearer feedback\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# --- Configuration for Aggressive Exploration Phase (Week 5) ---\n",
    "DATA_FILE_PATH = 'bbo_master_w05.csv'  # Updated for Week 5 data\n",
    "OUTPUT_INPUTS_FILE = 'add_data/week05_clean_inputs.json'\n",
    "MAX_ITERATIONS = 50  # Optimisation iterations for finding the next best point\n",
    "N_SAMPLES = 10000  # Samples for Acquisition Function optimisation\n",
    "\n",
    "# Define the search space boundaries (always 0 to 1 for all dimensions)\n",
    "BOUNDS = [(0.0, 1.0)] * 8\n",
    "\n",
    "WEEK_DIMENSIONS = {\n",
    "    1: 2, 2: 2, 3: 3, 4: 4,\n",
    "    5: 4, 6: 5, 7: 6, 8: 8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a708881-8d52-4e17-8f2d-996618b17416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Core Bayesian Optimisation Functions ---\n",
    "\n",
    "def load_and_preprocess_data(file_path: str, func_id: int) -> Tuple[np.ndarray, np.ndarray, StandardScaler, StandardScaler, int]:\n",
    "    \"\"\"\n",
    "    Loads and filters data for a specific function ID, strictly enforcing the \n",
    "    user-confirmed fixed dimension (d_fixed).\n",
    "    \n",
    "    Returns: X_scaled, Y_scaled, scaler_x, scaler_y, d_fixed (5 items)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_func = df[df['Function ID'] == func_id].copy()\n",
    "    \n",
    "    # Use the definitive fixed dimension for this function\n",
    "    d_fixed = WEEK_DIMENSIONS.get(func_id, 8) \n",
    "    \n",
    "    # 1. Prepare data for the GPR (only using columns up to d_fixed)\n",
    "    X_cols = [f'X{i}' for i in range(1, d_fixed + 1)]\n",
    "    X = df_func[X_cols].values\n",
    "    Y = df_func['Y'].values\n",
    "    \n",
    "    # Filter out any rows that still contain NaNs in the required X columns\n",
    "    valid_indices = ~np.isnan(X).any(axis=1)\n",
    "    X = X[valid_indices]\n",
    "    Y = Y[valid_indices]\n",
    "    \n",
    "    if len(Y) == 0:\n",
    "        raise ValueError(f\"No valid data points found for Function ID {func_id} after enforcing D={d_fixed}.\")\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    \n",
    "    # 1. Scale X data (critical for GPR)\n",
    "    scaler_x = StandardScaler()\n",
    "    X_scaled = scaler_x.fit_transform(X) \n",
    "    \n",
    "    # 2. Scale Y data (critical for GPR)\n",
    "    scaler_y = StandardScaler()\n",
    "    Y_scaled = scaler_y.fit_transform(Y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    logging.info(f\"Loaded {len(X)} points for F{func_id}. Fixed Dimension D={d_fixed} enforced.\")\n",
    "    \n",
    "    # Returns d_fixed as the dimension for consistency in the optimization loop\n",
    "    return X_scaled, Y_scaled, scaler_x, scaler_y, d_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7250ff75-3443-48d2-b3f7-544bdf1c27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_gpr_model(X: np.ndarray, Y: np.ndarray) -> GaussianProcessRegressor:\n",
    "    \"\"\"Builds and trains the Gaussian Process Regressor with a refined kernel.\"\"\"\n",
    "    \n",
    "    D = X.shape[1]\n",
    "    # Determine initial length scale based on the number of dimensions\n",
    "    initial_length_scale = np.sqrt(D) \n",
    "    \n",
    "    # Use the appropriate kernel structure for the D dimension\n",
    "    kernel = (\n",
    "        C(1.0, (1e-3, 1e3)) * RBF(\n",
    "            length_scale=[initial_length_scale] * D,\n",
    "            length_scale_bounds=(1e-5, 1e5)\n",
    "        )\n",
    "        + WhiteKernel(\n",
    "            noise_level=1e-5, \n",
    "            noise_level_bounds=(1e-10, 1e-1)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel, \n",
    "        alpha=0.0,\n",
    "        n_restarts_optimizer=20, \n",
    "        normalize_y=False\n",
    "    )\n",
    "    \n",
    "    gpr.fit(X, Y)\n",
    "    logging.info(f\"GPR Model Trained. Log-Marginal-Likelihood: {gpr.log_marginal_likelihood(gpr.kernel_.theta)}\")\n",
    "    return gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "926fd6ba-f5b2-4e76-80fc-7ed654329ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expected_improvement(X_candidate_scaled: np.ndarray, gpr: GaussianProcessRegressor, max_y: float) -> np.ndarray:\n",
    "    \"\"\"Calculates the Expected Improvement (EI) acquisition function for MAXIMISATION.\"\"\"\n",
    "    \n",
    "    # Predict mean and standard deviation\n",
    "    mu, sigma = gpr.predict(X_candidate_scaled.reshape(1, -1), return_std=True)\n",
    "    \n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    \n",
    "    if sigma <= 1e-10:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate Z-score for MAXIMISATION\n",
    "    Z = (mu - max_y) / sigma\n",
    "    \n",
    "    # Calculate EI\n",
    "    ei = sigma * (Z * norm.cdf(Z) + norm.pdf(Z))\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bce23808-d519-4cd8-a390-68579fa121d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def propose_next_point(gpr: GaussianProcessRegressor, func_id: int, d: int, scaler_x: StandardScaler, scaler_y: StandardScaler) -> List[float]:\n",
    "    \"\"\"Optimizes the acquisition function (EI) to find the next query point.\"\"\"\n",
    "    \n",
    "    # Optimization bounds are restricted to the current function dimension (d)\n",
    "    local_bounds = BOUNDS[:d]\n",
    "    \n",
    "    # 1. Calculate the best known MAXIMUM (Y_max) in the SCALED space\n",
    "    df_data = pd.read_csv(DATA_FILE_PATH)\n",
    "    # Filter by func_id\n",
    "    df_func = df_data[df_data['Function ID'] == func_id].copy() \n",
    "    Y = df_func['Y'].values\n",
    "    \n",
    "    # Recalculate scaled Y using the provided scaler_y (already fitted in load_and_preprocess_data)\n",
    "    Y_scaled = scaler_y.transform(Y.reshape(-1, 1)).flatten()\n",
    "    best_known_scaled = np.max(Y_scaled)\n",
    "    \n",
    "    logging.info(f\"Best known MAXIMUM (Scaled Y) for F{func_id}: {best_known_scaled:.4f}\")\n",
    "\n",
    "    # Objective function to MAXIMIZE EI (so we minimize -EI)\n",
    "    def objective_function(x):\n",
    "        # Scale the candidate point (x) using the provided scaler_x\n",
    "        # x is already size d, and scaler_x was fitted on size d\n",
    "        x_scaled = scaler_x.transform(x.reshape(1, -1)) \n",
    "        \n",
    "        # The objective is to maximize EI, so we return -EI\n",
    "        ei_value = expected_improvement(x_scaled, gpr, best_known_scaled)\n",
    "        \n",
    "        # Ensure we always return a float\n",
    "        return -ei_value if isinstance(ei_value, (int, float, np.float64)) else -1e-10\n",
    "\n",
    "    # 2. Optimization Phase: Use multi-start optimization\n",
    "    \n",
    "    # a. Randomly sample N_SAMPLES points in the search space [0, 1]\n",
    "    X_samples = np.random.uniform(local_bounds[0][0], local_bounds[0][1], \n",
    "                                  size=(N_SAMPLES, d))\n",
    "    \n",
    "    # b. Find the point with the highest EI among samples (good starting point)\n",
    "    X_samples_scaled = scaler_x.transform(X_samples)\n",
    "\n",
    "    # Calculate EI for all samples\n",
    "    ei_values = np.array([\n",
    "        expected_improvement(X_samples_scaled[i], gpr, best_known_scaled) \n",
    "        for i in range(N_SAMPLES)\n",
    "    ])\n",
    "    \n",
    "    # Initialize with the best sampled point\n",
    "    best_sample_index = np.argmax(ei_values)\n",
    "    best_ei = ei_values[best_sample_index]\n",
    "    best_x = X_samples[best_sample_index]\n",
    "    \n",
    "    # c. Run local optimization from the best sample point\n",
    "    \n",
    "    for i in range(MAX_ITERATIONS):\n",
    "        # Use random start point, or the best sampled point for the first run\n",
    "        x0 = best_x if i == 0 else np.random.uniform(local_bounds[0][0], local_bounds[0][1], size=d)\n",
    "        \n",
    "        if not isinstance(x0, np.ndarray):\n",
    "             x0 = np.array(x0, dtype=float)\n",
    "\n",
    "        res = minimize(\n",
    "            fun=objective_function,\n",
    "            x0=x0,\n",
    "            bounds=local_bounds,\n",
    "            method='L-BFGS-B' \n",
    "        )\n",
    "\n",
    "        # Check for successful optimization and a valid objective function result\n",
    "        if res.success and res.fun is not None:\n",
    "            current_ei = -res.fun\n",
    "            # Check for improvement\n",
    "            if current_ei > best_ei and not np.isclose(current_ei, best_ei):\n",
    "                best_ei = current_ei\n",
    "                best_x = res.x\n",
    "            \n",
    "    logging.info(f\"Optimal EI found: {best_ei:.4f}\")\n",
    "    \n",
    "    # Round the final proposal to 6 decimal places for submission\n",
    "    return np.round(best_x, 6).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09d438ee-ff4e-4bab-ae25-bdfe5574676a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_optimisation():\n",
    "    \"\"\"Main loop to run BO for all 8 functions and generate the output JSON file.\"\"\"\n",
    "    \n",
    "    all_inputs = []\n",
    "\n",
    "    # Iterate through all 8 functions (F1 to F8)\n",
    "    for func_id in range(1, 9):\n",
    "        logging.info(f\"\\n--- Processing Function F{func_id} ---\")\n",
    "        \n",
    "        current_d = WEEK_DIMENSIONS[func_id] # Use the fixed dimension\n",
    "        \n",
    "        try:\n",
    "            # 1. Load Data\n",
    "            # X_scaled will have the shape (N, D), where D=current_d\n",
    "            X_scaled, Y_scaled, scaler_x, scaler_y, d = load_and_preprocess_data(DATA_FILE_PATH, func_id)\n",
    "            \n",
    "            # 2. Train GPR Model\n",
    "            # The GPR is correctly trained on the full D dimension\n",
    "            gpr = build_gpr_model(X_scaled, Y_scaled)\n",
    "\n",
    "            # 3. Propose Next Point\n",
    "            # Propose the point across the full D-dimensional space\n",
    "            next_x_point = propose_next_point(gpr, func_id, d, scaler_x, scaler_y)\n",
    "\n",
    "            # 4. Format Input\n",
    "            # Pad to 8D for consistency in internal logging/arrays, but this is discarded in final JSON\n",
    "            full_input = next_x_point + [0.0] * (8 - d)\n",
    "            all_inputs.append(full_input)\n",
    "            \n",
    "            logging.info(f\"F{func_id} Proposed Query (D={d}): {next_x_point}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fallback uses the fixed dimension\n",
    "            logging.error(f\"An error occurred while processing F{func_id}: {e}\")\n",
    "            \n",
    "            default_x = [0.5] * current_d\n",
    "            # Pad to 8D for consistency\n",
    "            full_input = default_x + [0.0] * (8 - current_d)\n",
    "            all_inputs.append(full_input)\n",
    "            logging.warning(f\"F{func_id} failed. Inserting safe default (D={current_d}): {default_x}\")\n",
    "\n",
    "\n",
    "    # --- Final Output ---\n",
    "    logging.info(\"\\nINFO: ----------------------------------\")\n",
    "    logging.info(\"INFO: Saving Week 5 inputs to JSON...\")\n",
    "    \n",
    "    # Clean up the output to match the required format (list of lists, trimmed to fixed D)\n",
    "    cleaned_inputs = []\n",
    "    for i, row in enumerate(all_inputs, start=1):\n",
    "        # Use the standard, fixed dimension for the final output JSON submission\n",
    "        expected_d = WEEK_DIMENSIONS[i]\n",
    "        cleaned_inputs.append(row[:expected_d])\n",
    "        \n",
    "    try:\n",
    "        with open(OUTPUT_INPUTS_FILE, 'w') as f:\n",
    "            # Save as a pretty-printed JSON list\n",
    "            json.dump(cleaned_inputs, f, indent=2)\n",
    "            \n",
    "        logging.info(f\"INFO: Successfully generated 8 new query points in '{OUTPUT_INPUTS_FILE}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to write output JSON file: {e}\")\n",
    "\n",
    "    logging.info(\"INFO: Review the generated points and submit the JSON file.\")\n",
    "    logging.info(\"INFO: ----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f58b9b12-99c6-455d-87d5-06e892843c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "--- Processing Function F1 ---\n",
      "INFO: Loaded 14 points for F1. Fixed Dimension D=2 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.86513946486542\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F1: 3.3378\n",
      "INFO: Optimal EI found: 0.0001\n",
      "INFO: F1 Proposed Query (D=2): [0.598193, 0.70091]\n",
      "INFO: \n",
      "--- Processing Function F2 ---\n",
      "INFO: Loaded 14 points for F2. Fixed Dimension D=2 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -13.394454114593238\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F2: 1.6852\n",
      "INFO: Optimal EI found: 0.0267\n",
      "INFO: F2 Proposed Query (D=2): [0.208622, 0.315491]\n",
      "INFO: \n",
      "--- Processing Function F3 ---\n",
      "INFO: Loaded 14 points for F3. Fixed Dimension D=3 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -13.913514219752603\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F3: 1.1389\n",
      "INFO: Optimal EI found: 0.1750\n",
      "INFO: F3 Proposed Query (D=3): [0.573329, 0.0, 0.32048]\n",
      "INFO: \n",
      "--- Processing Function F4 ---\n",
      "INFO: Loaded 14 points for F4. Fixed Dimension D=4 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -16.547441869929056\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F4: 2.0936\n",
      "INFO: Optimal EI found: 0.1862\n",
      "INFO: F4 Proposed Query (D=4): [0.406574, 0.220158, 0.268444, 0.246611]\n",
      "INFO: \n",
      "--- Processing Function F5 ---\n",
      "INFO: Loaded 14 points for F5. Fixed Dimension D=4 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -5.965647677133552\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F5: 3.4899\n",
      "INFO: Optimal EI found: 0.0372\n",
      "INFO: F5 Proposed Query (D=4): [0.0, 1.0, 1.0, 0.0]\n",
      "INFO: \n",
      "--- Processing Function F6 ---\n",
      "INFO: Loaded 14 points for F6. Fixed Dimension D=5 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -14.373475757680232\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F6: 1.1790\n",
      "INFO: Optimal EI found: 0.5274\n",
      "INFO: F6 Proposed Query (D=5): [0.783269, 0.227788, 1.0, 0.716222, 0.55527]\n",
      "INFO: \n",
      "--- Processing Function F7 ---\n",
      "INFO: Loaded 14 points for F7. Fixed Dimension D=6 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -19.78396787015608\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F7: 2.4971\n",
      "INFO: Optimal EI found: 0.0755\n",
      "INFO: F7 Proposed Query (D=6): [0.554175, 0.604649, 0.1292, 0.611107, 0.485766, 0.840383]\n",
      "INFO: \n",
      "--- Processing Function F8 ---\n",
      "INFO: Loaded 14 points for F8. Fixed Dimension D=8 enforced.\n",
      "INFO: GPR Model Trained. Log-Marginal-Likelihood: -14.729149791165895\n",
      "INFO: Best known MAXIMUM (Scaled Y) for F8: 1.5482\n",
      "INFO: Optimal EI found: 0.2170\n",
      "INFO: F8 Proposed Query (D=8): [0.0, 0.804574, 0.266611, 0.136686, 0.656434, 0.355551, 0.0, 0.674748]\n",
      "INFO: \n",
      "INFO: ----------------------------------\n",
      "INFO: INFO: Saving Week 5 inputs to JSON...\n",
      "INFO: INFO: Successfully generated 8 new query points in 'add_data/week05_clean_inputs.json'.\n",
      "INFO: INFO: Review the generated points and submit the JSON file.\n",
      "INFO: INFO: ----------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_optimisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09084c5-e9fe-47b8-8f1a-79dc168359be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
